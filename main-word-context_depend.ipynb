{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from pathlib import Path\n",
    "import kaldi_io\n",
    "import math\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from lib.Data_show import Data_show\n",
    "from lib.Word_cla_Dataset import Word_cla_Dataset\n",
    "from lib.Decoder import Decoder\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据SLR85训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR_feats = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/Dataset/feats/SLR85/hifi_16k/train/feats.scp\") }\n",
    "SLR_feats_dev = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/Dataset/feats/SLR85/hifi_16k/dev/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_label = { u:d for u,d in kaldi_io.read_vec_int_ark(\"feats/ali.1.ph\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = { u:d for u,d in kaldi_io.read_mat_scp(\"../../git/phone_align_more_44k/train_fbank/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"你\"      \"好\"       \"米\"       \"雅\"\n",
    "129 63    61 27     128 64     92 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word =np.array([[128,62],[60,26], [127, 63], [91,68] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成word_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label={}\n",
    "for utt, label in phone_label.items():\n",
    "    word_label_tmp = np.zeros(label.shape[0]) \n",
    "    i = 0\n",
    "    while i < label.shape[0]:\n",
    "        finded = False\n",
    "        if label[i] in word[:,0]:\n",
    "            word_index = np.where(word == label[i])[0][0]\n",
    "            start = i\n",
    "            while i < label.shape[0]:\n",
    "                \n",
    "                if label[i] == label[start]:\n",
    "                    i += 1\n",
    "                elif label[i] == word[word_index][1]:\n",
    "                    finded = True\n",
    "                    end = i\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i -= 1\n",
    "                    break\n",
    "            \n",
    "            if finded:\n",
    "                word_label_tmp[start:end+1] = word_index+1\n",
    "                        \n",
    "                        \n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    word_label[utt] = word_label_tmp.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1, 128, 128, 128,  62,  62,  62,  60,  60,  60,  60,  60,\n",
       "        26,  26,  26,  26,  26,  26,  26,  26,  26,  26,   1,   1,   1,\n",
       "         1, 127, 127, 127,  63,  63,  63,  63,  91,  91,  68,  68,  68,\n",
       "        68,  68,  68,   1,   1,   1,   1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_label[\"SV0255_7_01_S3881\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0,\n",
       "       0, 0], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_label[\"SV0255_7_01_S3881\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_new={}\n",
    "for key,values in feats.items():\n",
    "    if \"SV\" not in key:\n",
    "        if random.random() < 0.4:\n",
    "            feats_new[key] = values\n",
    "feat_train = {**feats_new, **SLR_feats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_show:\n",
    "    class2word=[]\n",
    "    \n",
    "    def __init__(self, class2word =[\"other\", \"你\",\"好\",\"米\",\"雅\"]):\n",
    "        \n",
    "        Data_show.class2word = class2word\n",
    "\n",
    "\n",
    "    def show_softmax(self, pred_label_with_softmax):\n",
    "        \n",
    "        title = \"\"\n",
    "        for i in range(len(Data_show.class2word)):\n",
    "            title += \"\\t\" + Data_show.class2word[i]\n",
    "        \n",
    "        content = \"\"\n",
    "        for i in range(0,pred_label_with_softmax.shape[0]):\n",
    "            content += str(i) + \":\\t\"\n",
    "            for j in range(0,pred_label_with_softmax.shape[1]):\n",
    "                content += '%.2f\\t' %pred_label_with_softmax[i][j]\n",
    "            content += \"\\n\"\n",
    "     \n",
    "        return title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6fcef2fd131e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"IC0104W0039\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m367\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m367\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_new' is not defined"
     ]
    }
   ],
   "source": [
    "feat_new[\"IC0104W0039\"][367-20:367+10].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train = Word_cla_Dataset(word_label, feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23627 89330\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for key in word_label.keys():\n",
    "    if \"SV\" in key:\n",
    "        i += 1\n",
    "    else :\n",
    "        j += 1\n",
    "print(i ,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_dev = Word_cla_Dataset(word_label, SLR_feats_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train.word_label_nd[-75:-61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13814620, 1200)\n",
      "(13814620,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data_set_train.feats_nd.shape)\n",
    "print(data_set_train.word_label_nd.shape)\n",
    "print(data_set_train.word_label_nd[1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[13.633668, 13.99829 , 15.901409, ..., 13.34208 , 14.012131,\n",
       "         13.291359]], dtype=float32),\n",
       " array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train[100][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train[100][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.Tensor(data_set_train.feats_nd)#.to(device)\n",
    "train_label = torch.LongTensor(data_set_train.word_label_nd)#.to(device)\n",
    "dev_data = torch.Tensor(data_set_dev.feats_nd)#.to(device)\n",
    "dev_label = torch.LongTensor(data_set_dev.word_label_nd)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter(data)\n",
      " Counter({0: 11761262, 4: 707501, 2: 646999, 3: 444466, 1: 407874})\n"
     ]
    }
   ],
   "source": [
    "print('Counter(data)\\n',Counter(data_set_train.word_label_nd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.sigmoid(self.fc1(input))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001  #0.001\n",
    "EPOCH = 2      #400 best\n",
    "BATCH_SIZE = 150\n",
    "input_size=40*30\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13968102, 1200])\n",
      "torch.Size([13968102])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 1.5707216240167619 \tloss: 1.581739068031311\n",
      "total_loss: 1.5668513911366462 \tloss: 1.5658981800079346\n",
      "total_loss: 1.5659097527265549 \tloss: 1.5520520210266113\n",
      "total_loss: 1.5662817475795745 \tloss: 1.5839787721633911\n",
      "total_loss: 1.565831024825573 \tloss: 1.567136526107788\n",
      "total_loss: 1.5653219010233879 \tloss: 1.5240556001663208\n",
      "total_loss: 1.5636251400113106 \tloss: 1.5908160209655762\n",
      "total_loss: 1.5648815143704415 \tloss: 1.6106810569763184\n",
      "total_loss: 1.5648323717713355 \tloss: 1.5643868446350098\n",
      "total_loss: 1.5653951781988145 \tloss: 1.6069931983947754\n",
      "total_loss: 1.5655405352711678 \tloss: 1.6075032949447632\n",
      "total_loss: 1.5654067241549492 \tloss: 1.5709507465362549\n",
      "total_loss: 1.5655875853896142 \tloss: 1.5863605737686157\n",
      "total_loss: 1.5660399155020714 \tloss: 1.6260517835617065\n",
      "total_loss: 1.5643442229032516 \tloss: 1.5317611694335938\n",
      "total_loss: 1.5664346075057984 \tloss: 1.524701476097107\n",
      "total_loss: 1.5658028916716575 \tloss: 1.5197653770446777\n",
      "total_loss: 1.565809099316597 \tloss: 1.5023713111877441\n",
      "total_loss: 1.5658992291092872 \tloss: 1.52705979347229\n",
      "total_loss: 1.566180117547512 \tloss: 1.5735573768615723\n",
      "total_loss: 1.5647801607251168 \tloss: 1.5309549570083618\n",
      "total_loss: 1.5656988188028336 \tloss: 1.5422388315200806\n"
     ]
    }
   ],
   "source": [
    "training_set = Data.TensorDataset(train_data,\n",
    "                                  train_label)\n",
    "training_loader = Data.DataLoader(dataset=training_set,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=True)\n",
    "testing_set = Data.TensorDataset(dev_data,\n",
    "                                 dev_label)\n",
    "testing_loader = Data.DataLoader(dataset=testing_set,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     shuffle=False)\n",
    "model = DNN(input_size, num_classes)#.to(device)\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([3.5,3.0,3.0,2.5,2.5,5,2.0,2.5,1.5,1.0]).to(device))\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0,14.0,10.0,13.5,10.5]))#.to(device))\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCH):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    ite = 0\n",
    "    print_every = 2000\n",
    "    for (data, label) in training_loader:\n",
    "        ite +=1\n",
    "        data = data\n",
    "        label = label\n",
    "        pred_label = model(data)\n",
    "        loss = criterion(pred_label, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optim.step()\n",
    "        _, answer = torch.max(pred_label.data, 1)\n",
    "        total_train += label.size(0)\n",
    "        correct_train += (answer == label).sum()\n",
    "        if ite % print_every == 0:\n",
    "            print(\"total_loss:\",total_loss/print_every, \"\\tloss:\",loss.item())\n",
    "            total_loss=0\n",
    "    print('Epoch {:3d} Accuracy on training data: {}% ({}/{})'\n",
    "          .format(epoch, (100 * correct_train / total_train), correct_train, total_train))\n",
    "    # pytorch 0.4 feature, not calculate grad on test set\n",
    "    with torch.no_grad():\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        for (data, label) in testing_loader:\n",
    "            pred_label = model(data)\n",
    "            _, answer = torch.max(pred_label.data, 1)\n",
    "            total_test += label.size(0)\n",
    "            correct_test += (answer == label).sum()\n",
    "        print('          Accuracy on testing data: {}% ({}/{})'\n",
    "              .format((100 * correct_test / total_test), correct_test, total_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model.pkl')\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['miya_mcy', 'miya_mcy1', 'miya_mingzhang', 'miya_mingzhang1'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/workspace/align_44_1k/test_feat/feats.scp\")}\n",
    "test_feats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = test_feats[\"miya_mcy1\"]\n",
    "feats_list = []\n",
    "for i in range(20,feat.shape[0]-9):\n",
    "    input_data=feat[i-20:i+10].reshape(1,-1)\n",
    "    feats_list.append(input_data)\n",
    "feats_nd = np.concatenate(tuple(feats_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=30\n",
    "input_feat = feat[i-20:i+10].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feats = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/workspace/align_44_1k/test_feat/feats.scp\")}\n",
    "\n",
    "pred_label = model(torch.Tensor(feats_nd).to(device))\n",
    "_, answer = torch.max(pred_label.data, 1)\n",
    "answer_list=list(answer.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt='SV0296_7_01_S3895'\n",
    "# utt=\"SV0255_7_01_S3881\"\n",
    "# utt=list(phone_label.keys())[110]\n",
    "\n",
    "# label_list = list(phone_label_dev[utt])\n",
    "pred_label = model(torch.Tensor(SLR_feats_dev[utt]).to(device))\n",
    "_, answer = torch.max(pred_label.data, 1)\n",
    "answer_list=list(answer.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SV0296_7_01_S3900'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(SLR_feats_dev.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utt=list(feats_aishell.keys())[110]\n",
    "\n",
    "# label_list = list(feats_aishell[utt])\n",
    "# pred_label = model(torch.Tensor(feats_aishell[utt]))#.to(device)\n",
    "# _, answer = torch.max(pred_label.data, 1)\n",
    "# answer_list=list(answer.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将预测结果映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title, content = Data_show().show_softmax(torch.nn.Softmax()(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tother\t你\t好\t米\t雅 \n",
      " 0:\t0.98\t0.00\t0.01\t0.00\t0.00\t\n",
      "1:\t0.80\t0.13\t0.01\t0.02\t0.04\t\n",
      "2:\t0.96\t0.01\t0.02\t0.00\t0.01\t\n",
      "3:\t0.98\t0.00\t0.01\t0.00\t0.00\t\n",
      "4:\t0.99\t0.00\t0.01\t0.00\t0.00\t\n",
      "5:\t0.89\t0.02\t0.02\t0.01\t0.06\t\n",
      "6:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "7:\t0.99\t0.00\t0.00\t0.01\t0.00\t\n",
      "8:\t0.93\t0.03\t0.01\t0.01\t0.02\t\n",
      "9:\t0.27\t0.15\t0.06\t0.17\t0.34\t\n",
      "10:\t0.03\t0.50\t0.00\t0.47\t0.00\t\n",
      "11:\t0.02\t0.70\t0.00\t0.28\t0.00\t\n",
      "12:\t0.02\t0.70\t0.00\t0.29\t0.00\t\n",
      "13:\t0.00\t0.50\t0.00\t0.49\t0.00\t\n",
      "14:\t0.00\t0.28\t0.00\t0.71\t0.00\t\n",
      "15:\t0.00\t0.33\t0.00\t0.67\t0.00\t\n",
      "16:\t0.00\t0.41\t0.00\t0.59\t0.00\t\n",
      "17:\t0.00\t0.64\t0.00\t0.36\t0.00\t\n",
      "18:\t0.00\t0.31\t0.00\t0.65\t0.03\t\n",
      "19:\t0.00\t0.34\t0.00\t0.63\t0.02\t\n",
      "20:\t0.00\t0.31\t0.00\t0.67\t0.02\t\n",
      "21:\t0.00\t0.32\t0.00\t0.66\t0.01\t\n",
      "22:\t0.00\t0.33\t0.00\t0.64\t0.03\t\n",
      "23:\t0.00\t0.38\t0.00\t0.50\t0.11\t\n",
      "24:\t0.00\t0.31\t0.00\t0.47\t0.22\t\n",
      "25:\t0.01\t0.31\t0.00\t0.30\t0.37\t\n",
      "26:\t0.00\t0.37\t0.02\t0.36\t0.25\t\n",
      "27:\t0.00\t0.17\t0.05\t0.11\t0.66\t\n",
      "28:\t0.00\t0.09\t0.16\t0.02\t0.72\t\n",
      "29:\t0.00\t0.03\t0.32\t0.01\t0.64\t\n",
      "30:\t0.00\t0.01\t0.89\t0.00\t0.10\t\n",
      "31:\t0.00\t0.01\t0.92\t0.00\t0.07\t\n",
      "32:\t0.00\t0.00\t0.94\t0.00\t0.06\t\n",
      "33:\t0.00\t0.01\t0.93\t0.00\t0.06\t\n",
      "34:\t0.00\t0.00\t0.93\t0.00\t0.06\t\n",
      "35:\t0.00\t0.00\t0.98\t0.00\t0.02\t\n",
      "36:\t0.00\t0.00\t0.99\t0.00\t0.01\t\n",
      "37:\t0.00\t0.00\t0.99\t0.00\t0.01\t\n",
      "38:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "39:\t0.00\t0.00\t0.99\t0.00\t0.01\t\n",
      "40:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "41:\t0.00\t0.00\t0.99\t0.00\t0.01\t\n",
      "42:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "43:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "44:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "45:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "46:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "47:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "48:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "49:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "50:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "51:\t0.00\t0.00\t1.00\t0.00\t0.00\t\n",
      "52:\t0.01\t0.00\t0.99\t0.00\t0.00\t\n",
      "53:\t0.05\t0.00\t0.94\t0.00\t0.00\t\n",
      "54:\t0.00\t0.00\t0.99\t0.00\t0.00\t\n",
      "55:\t0.03\t0.00\t0.97\t0.00\t0.00\t\n",
      "56:\t0.17\t0.00\t0.83\t0.00\t0.00\t\n",
      "57:\t0.17\t0.00\t0.83\t0.00\t0.00\t\n",
      "58:\t0.12\t0.00\t0.88\t0.00\t0.00\t\n",
      "59:\t0.38\t0.00\t0.62\t0.00\t0.00\t\n",
      "60:\t0.56\t0.00\t0.43\t0.00\t0.00\t\n",
      "61:\t0.11\t0.00\t0.88\t0.00\t0.01\t\n",
      "62:\t0.12\t0.01\t0.86\t0.00\t0.01\t\n",
      "63:\t0.81\t0.00\t0.19\t0.00\t0.00\t\n",
      "64:\t0.81\t0.00\t0.19\t0.00\t0.00\t\n",
      "65:\t0.62\t0.00\t0.37\t0.00\t0.00\t\n",
      "66:\t0.11\t0.01\t0.84\t0.01\t0.03\t\n",
      "67:\t0.21\t0.01\t0.75\t0.00\t0.03\t\n",
      "68:\t0.93\t0.01\t0.03\t0.00\t0.02\t\n",
      "69:\t0.41\t0.04\t0.42\t0.02\t0.11\t\n",
      "70:\t0.21\t0.06\t0.45\t0.07\t0.21\t\n",
      "71:\t0.19\t0.08\t0.19\t0.07\t0.46\t\n",
      "72:\t0.25\t0.08\t0.27\t0.04\t0.36\t\n",
      "73:\t0.24\t0.08\t0.17\t0.04\t0.48\t\n",
      "74:\t0.64\t0.05\t0.12\t0.03\t0.16\t\n",
      "75:\t0.42\t0.06\t0.22\t0.03\t0.27\t\n",
      "76:\t0.19\t0.07\t0.19\t0.04\t0.51\t\n",
      "77:\t0.45\t0.07\t0.32\t0.03\t0.13\t\n",
      "78:\t0.80\t0.03\t0.06\t0.01\t0.10\t\n",
      "79:\t0.92\t0.01\t0.03\t0.01\t0.04\t\n",
      "80:\t0.89\t0.02\t0.03\t0.01\t0.05\t\n",
      "81:\t0.86\t0.04\t0.05\t0.01\t0.03\t\n",
      "82:\t0.77\t0.05\t0.03\t0.02\t0.14\t\n",
      "83:\t0.62\t0.27\t0.03\t0.04\t0.04\t\n",
      "84:\t0.78\t0.11\t0.03\t0.02\t0.06\t\n",
      "85:\t0.86\t0.04\t0.03\t0.01\t0.07\t\n",
      "86:\t0.92\t0.02\t0.01\t0.01\t0.05\t\n",
      "87:\t0.54\t0.20\t0.02\t0.03\t0.20\t\n",
      "88:\t0.61\t0.13\t0.04\t0.03\t0.19\t\n",
      "89:\t0.99\t0.00\t0.00\t0.01\t0.00\t\n",
      "90:\t0.94\t0.01\t0.01\t0.01\t0.03\t\n",
      "91:\t0.82\t0.04\t0.02\t0.01\t0.12\t\n",
      "92:\t0.89\t0.02\t0.02\t0.00\t0.07\t\n",
      "93:\t0.65\t0.19\t0.02\t0.03\t0.11\t\n",
      "94:\t0.27\t0.30\t0.00\t0.41\t0.01\t\n",
      "95:\t0.02\t0.30\t0.00\t0.67\t0.01\t\n",
      "96:\t0.02\t0.16\t0.00\t0.81\t0.00\t\n",
      "97:\t0.01\t0.22\t0.00\t0.76\t0.00\t\n",
      "98:\t0.02\t0.27\t0.00\t0.70\t0.00\t\n",
      "99:\t0.02\t0.21\t0.00\t0.76\t0.00\t\n",
      "100:\t0.01\t0.20\t0.00\t0.79\t0.00\t\n",
      "101:\t0.01\t0.26\t0.00\t0.73\t0.00\t\n",
      "102:\t0.01\t0.22\t0.00\t0.77\t0.00\t\n",
      "103:\t0.00\t0.56\t0.00\t0.43\t0.00\t\n",
      "104:\t0.00\t0.55\t0.00\t0.44\t0.01\t\n",
      "105:\t0.00\t0.38\t0.00\t0.62\t0.01\t\n",
      "106:\t0.00\t0.28\t0.00\t0.71\t0.01\t\n",
      "107:\t0.00\t0.28\t0.00\t0.70\t0.02\t\n",
      "108:\t0.00\t0.24\t0.00\t0.75\t0.01\t\n",
      "109:\t0.00\t0.30\t0.00\t0.69\t0.01\t\n",
      "110:\t0.00\t0.28\t0.00\t0.71\t0.01\t\n",
      "111:\t0.00\t0.27\t0.00\t0.72\t0.01\t\n",
      "112:\t0.00\t0.27\t0.00\t0.71\t0.02\t\n",
      "113:\t0.00\t0.26\t0.00\t0.72\t0.01\t\n",
      "114:\t0.00\t0.26\t0.00\t0.72\t0.01\t\n",
      "115:\t0.00\t0.24\t0.00\t0.74\t0.01\t\n",
      "116:\t0.00\t0.32\t0.00\t0.66\t0.02\t\n",
      "117:\t0.00\t0.31\t0.00\t0.67\t0.02\t\n",
      "118:\t0.00\t0.33\t0.00\t0.66\t0.02\t\n",
      "119:\t0.00\t0.41\t0.00\t0.57\t0.02\t\n",
      "120:\t0.00\t0.41\t0.00\t0.57\t0.02\t\n",
      "121:\t0.00\t0.32\t0.00\t0.64\t0.03\t\n",
      "122:\t0.00\t0.36\t0.00\t0.53\t0.11\t\n",
      "123:\t0.00\t0.32\t0.00\t0.55\t0.13\t\n",
      "124:\t0.00\t0.32\t0.00\t0.51\t0.16\t\n",
      "125:\t0.00\t0.34\t0.00\t0.48\t0.18\t\n",
      "126:\t0.00\t0.37\t0.00\t0.43\t0.20\t\n",
      "127:\t0.00\t0.39\t0.01\t0.41\t0.18\t\n",
      "128:\t0.00\t0.30\t0.01\t0.39\t0.29\t\n",
      "129:\t0.00\t0.22\t0.03\t0.26\t0.48\t\n",
      "130:\t0.01\t0.14\t0.05\t0.22\t0.58\t\n",
      "131:\t0.02\t0.04\t0.05\t0.02\t0.87\t\n",
      "132:\t0.01\t0.03\t0.07\t0.01\t0.88\t\n",
      "133:\t0.01\t0.01\t0.03\t0.01\t0.94\t\n",
      "134:\t0.02\t0.01\t0.08\t0.03\t0.86\t\n",
      "135:\t0.00\t0.01\t0.42\t0.00\t0.57\t\n",
      "136:\t0.01\t0.00\t0.09\t0.00\t0.90\t\n",
      "137:\t0.01\t0.00\t0.12\t0.00\t0.86\t\n",
      "138:\t0.00\t0.00\t0.19\t0.00\t0.80\t\n",
      "139:\t0.00\t0.00\t0.72\t0.00\t0.27\t\n",
      "140:\t0.00\t0.00\t0.61\t0.00\t0.38\t\n",
      "141:\t0.00\t0.00\t0.85\t0.00\t0.15\t\n",
      "142:\t0.00\t0.00\t0.86\t0.00\t0.13\t\n",
      "143:\t0.02\t0.02\t0.34\t0.01\t0.62\t\n",
      "144:\t0.02\t0.01\t0.62\t0.00\t0.35\t\n",
      "145:\t0.00\t0.00\t0.96\t0.00\t0.03\t\n",
      "146:\t0.07\t0.00\t0.87\t0.00\t0.06\t\n",
      "147:\t0.01\t0.00\t0.88\t0.00\t0.10\t\n",
      "148:\t0.01\t0.00\t0.91\t0.00\t0.08\t\n",
      "149:\t0.07\t0.00\t0.87\t0.00\t0.05\t\n",
      "150:\t0.25\t0.23\t0.05\t0.02\t0.44\t\n",
      "151:\t0.75\t0.02\t0.13\t0.01\t0.10\t\n",
      "152:\t0.34\t0.10\t0.18\t0.08\t0.30\t\n",
      "153:\t0.83\t0.03\t0.07\t0.06\t0.01\t\n",
      "154:\t0.64\t0.03\t0.22\t0.03\t0.08\t\n",
      "155:\t0.33\t0.05\t0.33\t0.05\t0.24\t\n",
      "156:\t0.36\t0.02\t0.52\t0.03\t0.07\t\n",
      "157:\t0.53\t0.02\t0.32\t0.05\t0.08\t\n",
      "158:\t0.36\t0.02\t0.53\t0.01\t0.07\t\n",
      "159:\t0.25\t0.05\t0.57\t0.03\t0.09\t\n",
      "160:\t0.30\t0.11\t0.29\t0.06\t0.25\t\n",
      "161:\t0.31\t0.00\t0.67\t0.01\t0.00\t\n",
      "162:\t0.32\t0.04\t0.58\t0.02\t0.03\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title,\"\\n\",content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_label[utt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### “你好米雅”测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_miya_test = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/Dataset/feats/SLR85/far_field/train/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_miya_test=list(feats_miya_test.keys())[420]\n",
    "# utt_aishell=\"IC0001W0406\"\n",
    "\n",
    "pred_label_miya_test = model(torch.Tensor(feats_miya_test[utt_miya_test]).to(device))\n",
    "_, answer_miya_test = torch.max(pred_label_miya_test.data, 1)\n",
    "answer_miya_test_list=list(answer_miya_test.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title, content = Data_show().show_softmax(torch.nn.Softmax()(pred_label_miya_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tother\t你\t好\t米\t雅\n",
      "0:\t0.37\t0.54\t0.01\t0.05\t0.03\t\n",
      "1:\t0.18\t0.59\t0.02\t0.09\t0.12\t\n",
      "2:\t0.15\t0.67\t0.01\t0.16\t0.01\t\n",
      "3:\t0.20\t0.55\t0.01\t0.05\t0.19\t\n",
      "4:\t0.17\t0.41\t0.15\t0.06\t0.20\t\n",
      "5:\t0.38\t0.38\t0.05\t0.07\t0.13\t\n",
      "6:\t0.86\t0.09\t0.02\t0.02\t0.01\t\n",
      "7:\t0.26\t0.60\t0.01\t0.04\t0.09\t\n",
      "8:\t0.87\t0.10\t0.00\t0.01\t0.01\t\n",
      "9:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "10:\t0.82\t0.15\t0.01\t0.02\t0.00\t\n",
      "11:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "12:\t0.99\t0.00\t0.00\t0.00\t0.00\t\n",
      "13:\t0.99\t0.00\t0.00\t0.01\t0.00\t\n",
      "14:\t0.71\t0.25\t0.01\t0.03\t0.01\t\n",
      "15:\t0.50\t0.43\t0.01\t0.03\t0.02\t\n",
      "16:\t0.53\t0.42\t0.01\t0.03\t0.02\t\n",
      "17:\t0.43\t0.50\t0.03\t0.04\t0.01\t\n",
      "18:\t0.95\t0.03\t0.00\t0.01\t0.00\t\n",
      "19:\t0.75\t0.19\t0.01\t0.04\t0.02\t\n",
      "20:\t0.45\t0.48\t0.01\t0.04\t0.02\t\n",
      "21:\t0.77\t0.17\t0.01\t0.02\t0.03\t\n",
      "22:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "23:\t0.24\t0.64\t0.01\t0.04\t0.07\t\n",
      "24:\t0.84\t0.13\t0.01\t0.02\t0.01\t\n",
      "25:\t0.54\t0.34\t0.02\t0.03\t0.08\t\n",
      "26:\t0.35\t0.54\t0.01\t0.04\t0.06\t\n",
      "27:\t0.99\t0.01\t0.00\t0.01\t0.00\t\n",
      "28:\t0.37\t0.47\t0.02\t0.04\t0.09\t\n",
      "29:\t0.98\t0.00\t0.01\t0.01\t0.00\t\n",
      "30:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "31:\t0.23\t0.52\t0.02\t0.09\t0.14\t\n",
      "32:\t0.93\t0.02\t0.01\t0.01\t0.03\t\n",
      "33:\t0.41\t0.41\t0.03\t0.04\t0.11\t\n",
      "34:\t0.75\t0.10\t0.01\t0.03\t0.11\t\n",
      "35:\t0.84\t0.06\t0.00\t0.04\t0.05\t\n",
      "36:\t0.53\t0.31\t0.00\t0.12\t0.04\t\n",
      "37:\t0.18\t0.55\t0.01\t0.23\t0.03\t\n",
      "38:\t0.96\t0.02\t0.00\t0.01\t0.00\t\n",
      "39:\t0.94\t0.02\t0.01\t0.03\t0.00\t\n",
      "40:\t0.92\t0.02\t0.00\t0.05\t0.00\t\n",
      "41:\t0.37\t0.14\t0.00\t0.46\t0.02\t\n",
      "42:\t0.54\t0.11\t0.00\t0.32\t0.02\t\n",
      "43:\t0.24\t0.17\t0.00\t0.58\t0.01\t\n",
      "44:\t0.01\t0.18\t0.00\t0.81\t0.01\t\n",
      "45:\t0.73\t0.08\t0.01\t0.17\t0.01\t\n",
      "46:\t0.40\t0.17\t0.00\t0.42\t0.01\t\n",
      "47:\t0.03\t0.29\t0.00\t0.64\t0.03\t\n",
      "48:\t0.04\t0.35\t0.00\t0.56\t0.04\t\n",
      "49:\t0.22\t0.16\t0.15\t0.03\t0.44\t\n",
      "50:\t0.25\t0.08\t0.13\t0.01\t0.53\t\n",
      "51:\t0.27\t0.09\t0.15\t0.02\t0.47\t\n",
      "52:\t0.45\t0.01\t0.28\t0.01\t0.25\t\n",
      "53:\t0.23\t0.02\t0.64\t0.00\t0.11\t\n",
      "54:\t0.08\t0.00\t0.87\t0.00\t0.04\t\n",
      "55:\t0.64\t0.00\t0.35\t0.00\t0.01\t\n",
      "56:\t0.52\t0.00\t0.47\t0.00\t0.01\t\n",
      "57:\t0.02\t0.00\t0.94\t0.00\t0.04\t\n",
      "58:\t0.03\t0.00\t0.94\t0.00\t0.03\t\n",
      "59:\t0.15\t0.00\t0.81\t0.00\t0.03\t\n",
      "60:\t0.01\t0.01\t0.96\t0.00\t0.02\t\n",
      "61:\t0.09\t0.03\t0.71\t0.01\t0.16\t\n",
      "62:\t0.08\t0.05\t0.62\t0.02\t0.23\t\n",
      "63:\t0.25\t0.02\t0.50\t0.03\t0.19\t\n",
      "64:\t0.08\t0.01\t0.44\t0.02\t0.44\t\n",
      "65:\t0.04\t0.01\t0.80\t0.02\t0.14\t\n",
      "66:\t0.09\t0.01\t0.66\t0.02\t0.21\t\n",
      "67:\t0.03\t0.01\t0.77\t0.01\t0.18\t\n",
      "68:\t0.02\t0.00\t0.93\t0.00\t0.05\t\n",
      "69:\t0.03\t0.00\t0.90\t0.00\t0.06\t\n",
      "70:\t0.06\t0.01\t0.77\t0.01\t0.15\t\n",
      "71:\t0.16\t0.00\t0.77\t0.00\t0.06\t\n",
      "72:\t0.06\t0.00\t0.88\t0.00\t0.05\t\n",
      "73:\t0.14\t0.01\t0.75\t0.01\t0.10\t\n",
      "74:\t0.04\t0.00\t0.89\t0.01\t0.06\t\n",
      "75:\t0.02\t0.00\t0.90\t0.00\t0.07\t\n",
      "76:\t0.07\t0.00\t0.85\t0.00\t0.07\t\n",
      "77:\t0.14\t0.01\t0.80\t0.01\t0.06\t\n",
      "78:\t0.04\t0.01\t0.83\t0.01\t0.11\t\n",
      "79:\t0.07\t0.01\t0.82\t0.01\t0.09\t\n",
      "80:\t0.08\t0.01\t0.84\t0.01\t0.06\t\n",
      "81:\t0.23\t0.01\t0.69\t0.01\t0.07\t\n",
      "82:\t0.07\t0.01\t0.83\t0.01\t0.08\t\n",
      "83:\t0.03\t0.02\t0.85\t0.01\t0.09\t\n",
      "84:\t0.04\t0.03\t0.82\t0.02\t0.10\t\n",
      "85:\t0.03\t0.02\t0.79\t0.02\t0.14\t\n",
      "86:\t0.04\t0.05\t0.11\t0.02\t0.78\t\n",
      "87:\t0.17\t0.08\t0.61\t0.02\t0.13\t\n",
      "88:\t0.18\t0.03\t0.72\t0.02\t0.06\t\n",
      "89:\t0.20\t0.26\t0.12\t0.04\t0.38\t\n",
      "90:\t0.94\t0.00\t0.04\t0.01\t0.01\t\n",
      "91:\t0.88\t0.02\t0.08\t0.01\t0.01\t\n",
      "92:\t0.21\t0.35\t0.16\t0.04\t0.23\t\n",
      "93:\t0.15\t0.20\t0.27\t0.04\t0.34\t\n",
      "94:\t0.39\t0.34\t0.10\t0.03\t0.13\t\n",
      "95:\t0.62\t0.28\t0.03\t0.02\t0.05\t\n",
      "96:\t0.97\t0.02\t0.00\t0.00\t0.00\t\n",
      "97:\t0.53\t0.34\t0.01\t0.02\t0.10\t\n",
      "98:\t0.29\t0.59\t0.03\t0.04\t0.06\t\n",
      "99:\t0.51\t0.42\t0.01\t0.02\t0.04\t\n",
      "100:\t0.92\t0.06\t0.00\t0.01\t0.00\t\n",
      "101:\t0.91\t0.07\t0.00\t0.01\t0.01\t\n",
      "102:\t0.43\t0.48\t0.02\t0.03\t0.05\t\n",
      "103:\t0.26\t0.58\t0.01\t0.04\t0.11\t\n",
      "104:\t0.27\t0.52\t0.02\t0.04\t0.15\t\n",
      "105:\t0.20\t0.66\t0.02\t0.05\t0.06\t\n",
      "106:\t0.15\t0.67\t0.04\t0.11\t0.04\t\n",
      "107:\t0.12\t0.70\t0.04\t0.12\t0.03\t\n",
      "108:\t0.17\t0.68\t0.02\t0.06\t0.06\t\n",
      "109:\t0.25\t0.52\t0.03\t0.05\t0.15\t\n",
      "110:\t0.23\t0.65\t0.01\t0.04\t0.07\t\n",
      "111:\t0.21\t0.48\t0.12\t0.05\t0.14\t\n",
      "112:\t0.20\t0.37\t0.07\t0.04\t0.32\t\n",
      "113:\t0.24\t0.53\t0.05\t0.05\t0.13\t\n",
      "114:\t0.51\t0.12\t0.01\t0.02\t0.34\t\n",
      "115:\t0.20\t0.36\t0.01\t0.03\t0.41\t\n",
      "116:\t0.16\t0.39\t0.15\t0.07\t0.23\t\n",
      "117:\t0.19\t0.52\t0.03\t0.08\t0.19\t\n",
      "118:\t0.16\t0.77\t0.00\t0.04\t0.03\t\n",
      "119:\t0.98\t0.01\t0.00\t0.00\t0.00\t\n",
      "120:\t0.55\t0.39\t0.01\t0.03\t0.02\t\n",
      "121:\t0.37\t0.55\t0.02\t0.05\t0.01\t\n",
      "122:\t0.40\t0.53\t0.01\t0.04\t0.03\t\n",
      "123:\t0.92\t0.05\t0.01\t0.01\t0.00\t\n",
      "124:\t0.92\t0.05\t0.01\t0.01\t0.00\t\n",
      "125:\t0.80\t0.15\t0.02\t0.03\t0.01\t\n",
      "126:\t0.61\t0.14\t0.00\t0.24\t0.01\t\n",
      "127:\t0.17\t0.24\t0.00\t0.58\t0.01\t\n",
      "128:\t0.62\t0.11\t0.00\t0.25\t0.02\t\n",
      "129:\t0.16\t0.28\t0.00\t0.51\t0.05\t\n",
      "130:\t0.27\t0.20\t0.00\t0.46\t0.06\t\n",
      "131:\t0.51\t0.16\t0.00\t0.30\t0.03\t\n",
      "132:\t0.59\t0.12\t0.00\t0.28\t0.01\t\n",
      "133:\t0.01\t0.16\t0.00\t0.76\t0.07\t\n",
      "134:\t0.29\t0.17\t0.00\t0.50\t0.04\t\n",
      "135:\t0.83\t0.04\t0.00\t0.11\t0.01\t\n",
      "136:\t0.63\t0.09\t0.00\t0.21\t0.06\t\n",
      "137:\t0.40\t0.14\t0.00\t0.43\t0.02\t\n",
      "138:\t0.13\t0.18\t0.00\t0.68\t0.01\t\n",
      "139:\t0.25\t0.18\t0.00\t0.55\t0.02\t\n",
      "140:\t0.02\t0.24\t0.00\t0.72\t0.02\t\n",
      "141:\t0.83\t0.05\t0.00\t0.11\t0.01\t\n",
      "142:\t0.92\t0.02\t0.00\t0.05\t0.01\t\n",
      "143:\t0.09\t0.22\t0.00\t0.67\t0.02\t\n",
      "144:\t0.06\t0.20\t0.00\t0.72\t0.01\t\n",
      "145:\t0.02\t0.17\t0.00\t0.80\t0.01\t\n",
      "146:\t0.41\t0.16\t0.00\t0.40\t0.04\t\n",
      "147:\t0.35\t0.16\t0.01\t0.43\t0.05\t\n",
      "148:\t0.05\t0.21\t0.00\t0.68\t0.05\t\n",
      "149:\t0.04\t0.25\t0.01\t0.42\t0.27\t\n",
      "150:\t0.80\t0.05\t0.01\t0.09\t0.05\t\n",
      "151:\t0.89\t0.03\t0.02\t0.02\t0.04\t\n",
      "152:\t0.65\t0.04\t0.03\t0.01\t0.27\t\n",
      "153:\t0.13\t0.10\t0.04\t0.01\t0.72\t\n",
      "154:\t0.98\t0.00\t0.00\t0.00\t0.01\t\n",
      "155:\t0.34\t0.01\t0.01\t0.00\t0.64\t\n",
      "156:\t0.05\t0.05\t0.02\t0.01\t0.88\t\n",
      "157:\t0.08\t0.06\t0.01\t0.01\t0.84\t\n",
      "158:\t0.03\t0.03\t0.01\t0.00\t0.93\t\n",
      "159:\t0.05\t0.04\t0.01\t0.01\t0.89\t\n",
      "160:\t0.09\t0.06\t0.01\t0.01\t0.84\t\n",
      "161:\t0.12\t0.04\t0.01\t0.01\t0.82\t\n",
      "162:\t0.13\t0.06\t0.05\t0.02\t0.74\t\n",
      "163:\t0.23\t0.34\t0.04\t0.03\t0.36\t\n",
      "164:\t0.20\t0.25\t0.10\t0.03\t0.42\t\n",
      "165:\t0.82\t0.02\t0.04\t0.01\t0.11\t\n",
      "166:\t0.20\t0.13\t0.15\t0.03\t0.48\t\n",
      "167:\t0.18\t0.28\t0.02\t0.02\t0.50\t\n",
      "168:\t0.11\t0.18\t0.01\t0.01\t0.69\t\n",
      "169:\t0.38\t0.06\t0.01\t0.01\t0.54\t\n",
      "170:\t0.16\t0.21\t0.04\t0.02\t0.56\t\n",
      "171:\t0.13\t0.17\t0.05\t0.02\t0.63\t\n",
      "172:\t0.31\t0.41\t0.01\t0.03\t0.24\t\n",
      "173:\t0.19\t0.26\t0.02\t0.02\t0.50\t\n",
      "174:\t0.15\t0.20\t0.01\t0.02\t0.63\t\n",
      "175:\t0.53\t0.02\t0.00\t0.01\t0.44\t\n",
      "176:\t0.17\t0.24\t0.02\t0.02\t0.55\t\n",
      "177:\t0.06\t0.10\t0.19\t0.04\t0.61\t\n",
      "178:\t0.05\t0.07\t0.14\t0.03\t0.72\t\n",
      "179:\t0.07\t0.10\t0.33\t0.04\t0.45\t\n",
      "180:\t0.08\t0.12\t0.07\t0.03\t0.70\t\n",
      "181:\t0.24\t0.20\t0.08\t0.03\t0.45\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats[utt_miya_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非“你好米雅”测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_aishell = { u:d for u,d in kaldi_io.read_mat_scp(\"../../wake_dnn_miya_only/feats_aishell2_test/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_aishell=list(feats_aishell.keys())[420]\n",
    "utt_aishell=\"IC0001W0406\"\n",
    "\n",
    "pred_label_aishell = model(torch.Tensor(feats_aishell[utt_aishell]).to(device))\n",
    "_, answer_aishell = torch.max(pred_label_aishell.data, 1)\n",
    "answer_aishell_list=list(answer_aishell.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title, content = Data_show().show_softmax(torch.nn.Softmax()(pred_label_miya_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tother\t你\t好\t米\t雅\n",
      "0:\t0.37\t0.54\t0.01\t0.05\t0.03\t\n",
      "1:\t0.18\t0.59\t0.02\t0.09\t0.12\t\n",
      "2:\t0.15\t0.67\t0.01\t0.16\t0.01\t\n",
      "3:\t0.20\t0.55\t0.01\t0.05\t0.19\t\n",
      "4:\t0.17\t0.41\t0.15\t0.06\t0.20\t\n",
      "5:\t0.38\t0.38\t0.05\t0.07\t0.13\t\n",
      "6:\t0.86\t0.09\t0.02\t0.02\t0.01\t\n",
      "7:\t0.26\t0.60\t0.01\t0.04\t0.09\t\n",
      "8:\t0.87\t0.10\t0.00\t0.01\t0.01\t\n",
      "9:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "10:\t0.82\t0.15\t0.01\t0.02\t0.00\t\n",
      "11:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "12:\t0.99\t0.00\t0.00\t0.00\t0.00\t\n",
      "13:\t0.99\t0.00\t0.00\t0.01\t0.00\t\n",
      "14:\t0.71\t0.25\t0.01\t0.03\t0.01\t\n",
      "15:\t0.50\t0.43\t0.01\t0.03\t0.02\t\n",
      "16:\t0.53\t0.42\t0.01\t0.03\t0.02\t\n",
      "17:\t0.43\t0.50\t0.03\t0.04\t0.01\t\n",
      "18:\t0.95\t0.03\t0.00\t0.01\t0.00\t\n",
      "19:\t0.75\t0.19\t0.01\t0.04\t0.02\t\n",
      "20:\t0.45\t0.48\t0.01\t0.04\t0.02\t\n",
      "21:\t0.77\t0.17\t0.01\t0.02\t0.03\t\n",
      "22:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "23:\t0.24\t0.64\t0.01\t0.04\t0.07\t\n",
      "24:\t0.84\t0.13\t0.01\t0.02\t0.01\t\n",
      "25:\t0.54\t0.34\t0.02\t0.03\t0.08\t\n",
      "26:\t0.35\t0.54\t0.01\t0.04\t0.06\t\n",
      "27:\t0.99\t0.01\t0.00\t0.01\t0.00\t\n",
      "28:\t0.37\t0.47\t0.02\t0.04\t0.09\t\n",
      "29:\t0.98\t0.00\t0.01\t0.01\t0.00\t\n",
      "30:\t0.98\t0.01\t0.00\t0.01\t0.00\t\n",
      "31:\t0.23\t0.52\t0.02\t0.09\t0.14\t\n",
      "32:\t0.93\t0.02\t0.01\t0.01\t0.03\t\n",
      "33:\t0.41\t0.41\t0.03\t0.04\t0.11\t\n",
      "34:\t0.75\t0.10\t0.01\t0.03\t0.11\t\n",
      "35:\t0.84\t0.06\t0.00\t0.04\t0.05\t\n",
      "36:\t0.53\t0.31\t0.00\t0.12\t0.04\t\n",
      "37:\t0.18\t0.55\t0.01\t0.23\t0.03\t\n",
      "38:\t0.96\t0.02\t0.00\t0.01\t0.00\t\n",
      "39:\t0.94\t0.02\t0.01\t0.03\t0.00\t\n",
      "40:\t0.92\t0.02\t0.00\t0.05\t0.00\t\n",
      "41:\t0.37\t0.14\t0.00\t0.46\t0.02\t\n",
      "42:\t0.54\t0.11\t0.00\t0.32\t0.02\t\n",
      "43:\t0.24\t0.17\t0.00\t0.58\t0.01\t\n",
      "44:\t0.01\t0.18\t0.00\t0.81\t0.01\t\n",
      "45:\t0.73\t0.08\t0.01\t0.17\t0.01\t\n",
      "46:\t0.40\t0.17\t0.00\t0.42\t0.01\t\n",
      "47:\t0.03\t0.29\t0.00\t0.64\t0.03\t\n",
      "48:\t0.04\t0.35\t0.00\t0.56\t0.04\t\n",
      "49:\t0.22\t0.16\t0.15\t0.03\t0.44\t\n",
      "50:\t0.25\t0.08\t0.13\t0.01\t0.53\t\n",
      "51:\t0.27\t0.09\t0.15\t0.02\t0.47\t\n",
      "52:\t0.45\t0.01\t0.28\t0.01\t0.25\t\n",
      "53:\t0.23\t0.02\t0.64\t0.00\t0.11\t\n",
      "54:\t0.08\t0.00\t0.87\t0.00\t0.04\t\n",
      "55:\t0.64\t0.00\t0.35\t0.00\t0.01\t\n",
      "56:\t0.52\t0.00\t0.47\t0.00\t0.01\t\n",
      "57:\t0.02\t0.00\t0.94\t0.00\t0.04\t\n",
      "58:\t0.03\t0.00\t0.94\t0.00\t0.03\t\n",
      "59:\t0.15\t0.00\t0.81\t0.00\t0.03\t\n",
      "60:\t0.01\t0.01\t0.96\t0.00\t0.02\t\n",
      "61:\t0.09\t0.03\t0.71\t0.01\t0.16\t\n",
      "62:\t0.08\t0.05\t0.62\t0.02\t0.23\t\n",
      "63:\t0.25\t0.02\t0.50\t0.03\t0.19\t\n",
      "64:\t0.08\t0.01\t0.44\t0.02\t0.44\t\n",
      "65:\t0.04\t0.01\t0.80\t0.02\t0.14\t\n",
      "66:\t0.09\t0.01\t0.66\t0.02\t0.21\t\n",
      "67:\t0.03\t0.01\t0.77\t0.01\t0.18\t\n",
      "68:\t0.02\t0.00\t0.93\t0.00\t0.05\t\n",
      "69:\t0.03\t0.00\t0.90\t0.00\t0.06\t\n",
      "70:\t0.06\t0.01\t0.77\t0.01\t0.15\t\n",
      "71:\t0.16\t0.00\t0.77\t0.00\t0.06\t\n",
      "72:\t0.06\t0.00\t0.88\t0.00\t0.05\t\n",
      "73:\t0.14\t0.01\t0.75\t0.01\t0.10\t\n",
      "74:\t0.04\t0.00\t0.89\t0.01\t0.06\t\n",
      "75:\t0.02\t0.00\t0.90\t0.00\t0.07\t\n",
      "76:\t0.07\t0.00\t0.85\t0.00\t0.07\t\n",
      "77:\t0.14\t0.01\t0.80\t0.01\t0.06\t\n",
      "78:\t0.04\t0.01\t0.83\t0.01\t0.11\t\n",
      "79:\t0.07\t0.01\t0.82\t0.01\t0.09\t\n",
      "80:\t0.08\t0.01\t0.84\t0.01\t0.06\t\n",
      "81:\t0.23\t0.01\t0.69\t0.01\t0.07\t\n",
      "82:\t0.07\t0.01\t0.83\t0.01\t0.08\t\n",
      "83:\t0.03\t0.02\t0.85\t0.01\t0.09\t\n",
      "84:\t0.04\t0.03\t0.82\t0.02\t0.10\t\n",
      "85:\t0.03\t0.02\t0.79\t0.02\t0.14\t\n",
      "86:\t0.04\t0.05\t0.11\t0.02\t0.78\t\n",
      "87:\t0.17\t0.08\t0.61\t0.02\t0.13\t\n",
      "88:\t0.18\t0.03\t0.72\t0.02\t0.06\t\n",
      "89:\t0.20\t0.26\t0.12\t0.04\t0.38\t\n",
      "90:\t0.94\t0.00\t0.04\t0.01\t0.01\t\n",
      "91:\t0.88\t0.02\t0.08\t0.01\t0.01\t\n",
      "92:\t0.21\t0.35\t0.16\t0.04\t0.23\t\n",
      "93:\t0.15\t0.20\t0.27\t0.04\t0.34\t\n",
      "94:\t0.39\t0.34\t0.10\t0.03\t0.13\t\n",
      "95:\t0.62\t0.28\t0.03\t0.02\t0.05\t\n",
      "96:\t0.97\t0.02\t0.00\t0.00\t0.00\t\n",
      "97:\t0.53\t0.34\t0.01\t0.02\t0.10\t\n",
      "98:\t0.29\t0.59\t0.03\t0.04\t0.06\t\n",
      "99:\t0.51\t0.42\t0.01\t0.02\t0.04\t\n",
      "100:\t0.92\t0.06\t0.00\t0.01\t0.00\t\n",
      "101:\t0.91\t0.07\t0.00\t0.01\t0.01\t\n",
      "102:\t0.43\t0.48\t0.02\t0.03\t0.05\t\n",
      "103:\t0.26\t0.58\t0.01\t0.04\t0.11\t\n",
      "104:\t0.27\t0.52\t0.02\t0.04\t0.15\t\n",
      "105:\t0.20\t0.66\t0.02\t0.05\t0.06\t\n",
      "106:\t0.15\t0.67\t0.04\t0.11\t0.04\t\n",
      "107:\t0.12\t0.70\t0.04\t0.12\t0.03\t\n",
      "108:\t0.17\t0.68\t0.02\t0.06\t0.06\t\n",
      "109:\t0.25\t0.52\t0.03\t0.05\t0.15\t\n",
      "110:\t0.23\t0.65\t0.01\t0.04\t0.07\t\n",
      "111:\t0.21\t0.48\t0.12\t0.05\t0.14\t\n",
      "112:\t0.20\t0.37\t0.07\t0.04\t0.32\t\n",
      "113:\t0.24\t0.53\t0.05\t0.05\t0.13\t\n",
      "114:\t0.51\t0.12\t0.01\t0.02\t0.34\t\n",
      "115:\t0.20\t0.36\t0.01\t0.03\t0.41\t\n",
      "116:\t0.16\t0.39\t0.15\t0.07\t0.23\t\n",
      "117:\t0.19\t0.52\t0.03\t0.08\t0.19\t\n",
      "118:\t0.16\t0.77\t0.00\t0.04\t0.03\t\n",
      "119:\t0.98\t0.01\t0.00\t0.00\t0.00\t\n",
      "120:\t0.55\t0.39\t0.01\t0.03\t0.02\t\n",
      "121:\t0.37\t0.55\t0.02\t0.05\t0.01\t\n",
      "122:\t0.40\t0.53\t0.01\t0.04\t0.03\t\n",
      "123:\t0.92\t0.05\t0.01\t0.01\t0.00\t\n",
      "124:\t0.92\t0.05\t0.01\t0.01\t0.00\t\n",
      "125:\t0.80\t0.15\t0.02\t0.03\t0.01\t\n",
      "126:\t0.61\t0.14\t0.00\t0.24\t0.01\t\n",
      "127:\t0.17\t0.24\t0.00\t0.58\t0.01\t\n",
      "128:\t0.62\t0.11\t0.00\t0.25\t0.02\t\n",
      "129:\t0.16\t0.28\t0.00\t0.51\t0.05\t\n",
      "130:\t0.27\t0.20\t0.00\t0.46\t0.06\t\n",
      "131:\t0.51\t0.16\t0.00\t0.30\t0.03\t\n",
      "132:\t0.59\t0.12\t0.00\t0.28\t0.01\t\n",
      "133:\t0.01\t0.16\t0.00\t0.76\t0.07\t\n",
      "134:\t0.29\t0.17\t0.00\t0.50\t0.04\t\n",
      "135:\t0.83\t0.04\t0.00\t0.11\t0.01\t\n",
      "136:\t0.63\t0.09\t0.00\t0.21\t0.06\t\n",
      "137:\t0.40\t0.14\t0.00\t0.43\t0.02\t\n",
      "138:\t0.13\t0.18\t0.00\t0.68\t0.01\t\n",
      "139:\t0.25\t0.18\t0.00\t0.55\t0.02\t\n",
      "140:\t0.02\t0.24\t0.00\t0.72\t0.02\t\n",
      "141:\t0.83\t0.05\t0.00\t0.11\t0.01\t\n",
      "142:\t0.92\t0.02\t0.00\t0.05\t0.01\t\n",
      "143:\t0.09\t0.22\t0.00\t0.67\t0.02\t\n",
      "144:\t0.06\t0.20\t0.00\t0.72\t0.01\t\n",
      "145:\t0.02\t0.17\t0.00\t0.80\t0.01\t\n",
      "146:\t0.41\t0.16\t0.00\t0.40\t0.04\t\n",
      "147:\t0.35\t0.16\t0.01\t0.43\t0.05\t\n",
      "148:\t0.05\t0.21\t0.00\t0.68\t0.05\t\n",
      "149:\t0.04\t0.25\t0.01\t0.42\t0.27\t\n",
      "150:\t0.80\t0.05\t0.01\t0.09\t0.05\t\n",
      "151:\t0.89\t0.03\t0.02\t0.02\t0.04\t\n",
      "152:\t0.65\t0.04\t0.03\t0.01\t0.27\t\n",
      "153:\t0.13\t0.10\t0.04\t0.01\t0.72\t\n",
      "154:\t0.98\t0.00\t0.00\t0.00\t0.01\t\n",
      "155:\t0.34\t0.01\t0.01\t0.00\t0.64\t\n",
      "156:\t0.05\t0.05\t0.02\t0.01\t0.88\t\n",
      "157:\t0.08\t0.06\t0.01\t0.01\t0.84\t\n",
      "158:\t0.03\t0.03\t0.01\t0.00\t0.93\t\n",
      "159:\t0.05\t0.04\t0.01\t0.01\t0.89\t\n",
      "160:\t0.09\t0.06\t0.01\t0.01\t0.84\t\n",
      "161:\t0.12\t0.04\t0.01\t0.01\t0.82\t\n",
      "162:\t0.13\t0.06\t0.05\t0.02\t0.74\t\n",
      "163:\t0.23\t0.34\t0.04\t0.03\t0.36\t\n",
      "164:\t0.20\t0.25\t0.10\t0.03\t0.42\t\n",
      "165:\t0.82\t0.02\t0.04\t0.01\t0.11\t\n",
      "166:\t0.20\t0.13\t0.15\t0.03\t0.48\t\n",
      "167:\t0.18\t0.28\t0.02\t0.02\t0.50\t\n",
      "168:\t0.11\t0.18\t0.01\t0.01\t0.69\t\n",
      "169:\t0.38\t0.06\t0.01\t0.01\t0.54\t\n",
      "170:\t0.16\t0.21\t0.04\t0.02\t0.56\t\n",
      "171:\t0.13\t0.17\t0.05\t0.02\t0.63\t\n",
      "172:\t0.31\t0.41\t0.01\t0.03\t0.24\t\n",
      "173:\t0.19\t0.26\t0.02\t0.02\t0.50\t\n",
      "174:\t0.15\t0.20\t0.01\t0.02\t0.63\t\n",
      "175:\t0.53\t0.02\t0.00\t0.01\t0.44\t\n",
      "176:\t0.17\t0.24\t0.02\t0.02\t0.55\t\n",
      "177:\t0.06\t0.10\t0.19\t0.04\t0.61\t\n",
      "178:\t0.05\t0.07\t0.14\t0.03\t0.72\t\n",
      "179:\t0.07\t0.10\t0.33\t0.04\t0.45\t\n",
      "180:\t0.08\t0.12\t0.07\t0.03\t0.70\t\n",
      "181:\t0.24\t0.20\t0.08\t0.03\t0.45\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_aishell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to(\"cpu\"), 'model.pkl')\n",
    "model1 = torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.jit.script(model1)\n",
    "sm.save(\"phone_cla_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1={1:\"1-1\",2:\"2-1\",3:\"3-1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2={2:\"2-2\",3:\"3-2\",4:\"4-2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{**map1,**map2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{**map2,**map1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
