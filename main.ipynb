{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from pathlib import Path\n",
    "import kaldi_io\n",
    "import math\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from lib.Data_show import Data_show\n",
    "from lib.Phone_cla_Dataset import Phone_cla_Dataset\n",
    "from lib.Decoder import Decoder\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_label = { u:d for u,d in kaldi_io.read_vec_int_ark(\"feats/ali_chain.1.ph\") }\n",
    "feats = { u:d for u,d in kaldi_io.read_mat_scp(\"../wake_up_align_sil_shared_recorp/train_fbank/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96489\n",
      "96489\n"
     ]
    }
   ],
   "source": [
    "print(len(feats))\n",
    "print(len(phone_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 3: 0, 129: 1, 63: 2, 61: 3, 27: 4, 128: 5, 64: 6, 92: 7, 69: 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_show().phone2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\t 0 \t 0\n",
      "i:\t 1 \t 0\n",
      "i:\t 2 \t 1\n",
      "i:\t 3 \t 1\n",
      "i:\t 4 \t 1\n",
      "i:\t 5 \t 2\n",
      "i:\t 6 \t 2\n",
      "i:\t 7 \t 2\n",
      "i:\t 8 \t 3\n",
      "i:\t 9 \t 3\n",
      "i:\t 10 \t 3\n",
      "i:\t 11 \t 4\n",
      "i:\t 12 \t 4\n",
      "i:\t 13 \t 4\n",
      "i:\t 14 \t 5\n",
      "i:\t 15 \t 5\n",
      "i:\t 16 \t 5\n",
      "i:\t 17 \t 6\n",
      "i:\t 18 \t 6\n",
      "i:\t 19 \t 6\n",
      "i:\t 20 \t 7\n",
      "i:\t 21 \t 7\n",
      "i:\t 22 \t 7\n",
      "i:\t 23 \t 8\n",
      "i:\t 24 \t 8\n",
      "i:\t 25 \t 8\n",
      "i:\t 26 \t 9\n",
      "i:\t 27 \t 9\n",
      "i:\t 28 \t 9\n",
      "i:\t 29 \t 10\n",
      "i:\t 30 \t 10\n",
      "i:\t 31 \t 10\n",
      "i:\t 32 \t 11\n",
      "i:\t 33 \t 11\n",
      "i:\t 34 \t 11\n",
      "i:\t 35 \t 12\n",
      "i:\t 36 \t 12\n",
      "i:\t 37 \t 12\n",
      "i:\t 38 \t 13\n",
      "i:\t 39 \t 13\n",
      "i:\t 40 \t 13\n",
      "i:\t 41 \t 14\n",
      "i:\t 42 \t 14\n",
      "i:\t 43 \t 14\n",
      "i:\t 44 \t 15\n",
      "i:\t 45 \t 15\n",
      "i:\t 46 \t 15\n",
      "i:\t 47 \t 16\n",
      "i:\t 48 \t 16\n",
      "i:\t 49 \t 16\n",
      "i:\t 50 \t 17\n",
      "i:\t 51 \t 17\n",
      "i:\t 52 \t 17\n",
      "i:\t 53 \t 18\n",
      "i:\t 54 \t 18\n",
      "i:\t 55 \t 18\n",
      "i:\t 56 \t 19\n",
      "i:\t 57 \t 19\n",
      "i:\t 58 \t 19\n",
      "i:\t 59 \t 20\n",
      "i:\t 60 \t 20\n",
      "i:\t 61 \t 20\n",
      "i:\t 62 \t 21\n",
      "i:\t 63 \t 21\n",
      "i:\t 64 \t 21\n",
      "i:\t 65 \t 22\n",
      "i:\t 66 \t 22\n",
      "i:\t 67 \t 22\n",
      "i:\t 68 \t 23\n",
      "i:\t 69 \t 23\n",
      "i:\t 70 \t 23\n",
      "i:\t 71 \t 24\n",
      "i:\t 72 \t 24\n",
      "i:\t 73 \t 24\n",
      "i:\t 74 \t 25\n",
      "i:\t 75 \t 25\n",
      "i:\t 76 \t 25\n",
      "i:\t 77 \t 26\n",
      "i:\t 78 \t 26\n",
      "i:\t 79 \t 26\n",
      "i:\t 80 \t 27\n",
      "i:\t 81 \t 27\n",
      "i:\t 82 \t 27\n",
      "i:\t 83 \t 28\n",
      "i:\t 84 \t 28\n",
      "i:\t 85 \t 28\n",
      "i:\t 86 \t 29\n",
      "i:\t 87 \t 29\n",
      "i:\t 88 \t 29\n",
      "i:\t 89 \t 30\n",
      "i:\t 90 \t 30\n",
      "i:\t 91 \t 30\n",
      "i:\t 92 \t 31\n",
      "i:\t 93 \t 31\n",
      "i:\t 94 \t 31\n",
      "i:\t 95 \t 32\n",
      "i:\t 96 \t 32\n",
      "i:\t 97 \t 32\n",
      "i:\t 98 \t 33\n",
      "i:\t 99 \t 33\n",
      "i:\t 100 \t 33\n",
      "i:\t 101 \t 34\n",
      "i:\t 102 \t 34\n",
      "i:\t 103 \t 34\n",
      "i:\t 104 \t 35\n",
      "i:\t 105 \t 35\n",
      "i:\t 106 \t 35\n",
      "i:\t 107 \t 36\n",
      "i:\t 108 \t 36\n",
      "i:\t 109 \t 36\n",
      "i:\t 110 \t 37\n",
      "i:\t 111 \t 37\n",
      "i:\t 112 \t 37\n",
      "i:\t 113 \t 38\n",
      "i:\t 114 \t 38\n",
      "i:\t 115 \t 38\n",
      "i:\t 116 \t 39\n",
      "i:\t 117 \t 39\n",
      "i:\t 118 \t 39\n",
      "i:\t 119 \t 40\n",
      "i:\t 120 \t 40\n",
      "i:\t 121 \t 40\n",
      "i:\t 122 \t 41\n",
      "i:\t 123 \t 41\n",
      "i:\t 124 \t 41\n",
      "i:\t 125 \t 42\n",
      "i:\t 126 \t 42\n",
      "i:\t 127 \t 42\n",
      "i:\t 128 \t 43\n",
      "i:\t 129 \t 43\n",
      "i:\t 130 \t 43\n",
      "i:\t 131 \t 44\n",
      "i:\t 132 \t 44\n",
      "i:\t 133 \t 44\n",
      "i:\t 134 \t 45\n",
      "i:\t 135 \t 45\n",
      "i:\t 136 \t 45\n",
      "i:\t 137 \t 46\n",
      "i:\t 138 \t 46\n",
      "i:\t 139 \t 46\n",
      "i:\t 140 \t 47\n",
      "i:\t 141 \t 47\n",
      "i:\t 142 \t 47\n"
     ]
    }
   ],
   "source": [
    "utt=\"SV0287_6_15_N3046\"\n",
    "a=np.zeros(feats[utt].shape[0], int)\n",
    "for i in range(a.shape[0]):\n",
    "    print(\"i:\\t\", i, \"\\t\",(i+1)//3)\n",
    "    a[i]=phone_label[utt][(i)//3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train = Phone_cla_Dataset(phone_label, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 5, 5, 6, 6, 7, 7, 8, 8, 8, 8, 8,\n",
       "       8, 8, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phone_cla_Dataset.class_trans_vector(phone_label[\"SV0287_6_15_N3046\"]) #Phone_cla_Dataset初始化之后可使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train.phone_label_nd[20:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23377008, 40)\n",
      "(23377008,)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(data_set_train.feats_nd.shape)\n",
    "print(data_set_train.phone_label_nd.shape)\n",
    "print(data_set_train.phone_label_nd[14440478])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.Tensor(data_set_train.feats_nd).to(device)\n",
    "train_label = torch.LongTensor(data_set_train.phone_label_nd).to(device)\n",
    "# test_data = torch.Tensor(data_set_dev.feats_nd).to(device)\n",
    "# test_label = torch.LongTensor(data_set_dev.phone_label_nd).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.sigmoid(self.fc1(input))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001  #0.001\n",
    "EPOCH = 10        #400 best\n",
    "BATCH_SIZE = 150\n",
    "input_size=40\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# prepare the data loader\n",
    "training_set = Data.TensorDataset(train_data,\n",
    "                                  train_label)\n",
    "training_loader = Data.DataLoader(dataset=training_set,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=True)\n",
    "# testing_set = Data.TensorDataset(test_data,\n",
    "#                                  test_label)\n",
    "# testing_loader = Data.DataLoader(dataset=testing_set,\n",
    "#                                      batch_size=BATCH_SIZE,\n",
    "#                                      shuffle=False)\n",
    "model = DNN(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCH):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    ite = 0\n",
    "    print_every = 2000\n",
    "    for (data, label) in training_loader:\n",
    "        ite +=1\n",
    "        data = data\n",
    "        label = label\n",
    "        pred_label = model(data)\n",
    "        loss = criterion(pred_label, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optim.step()\n",
    "        _, answer = torch.max(pred_label.data, 1)\n",
    "        total_train += label.size(0)\n",
    "        correct_train += (answer == label).sum()\n",
    "        if ite % print_every == 0:\n",
    "            print(\"total_loss:\",total_loss/print_every, \"\\tloss:\",loss.item())\n",
    "            total_loss=0\n",
    "    print('Epoch {:3d} Accuracy on training data: {}% ({}/{})'\n",
    "          .format(epoch, (100 * correct_train / total_train), correct_train, total_train))\n",
    "    # pytorch 0.4 feature, not calculate grad on test set\n",
    "#     with torch.no_grad():\n",
    "#         correct_test = 0\n",
    "#         total_test = 0\n",
    "#         for (data, label) in testing_loader:\n",
    "#             pred_label = model(data)\n",
    "#             _, answer = torch.max(pred_label.data, 1)\n",
    "#             total_test += label.size(0)\n",
    "#             correct_test += (answer == label).sum()\n",
    "#         print('          Accuracy on testing data: {}% ({}/{})'\n",
    "#               .format((100 * correct_test / total_test), correct_test, total_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pkl')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utt='SV0255_2_00_F0021'\n",
    "# utt=\"SV0255_2_07_S1082\"\n",
    "utt=list(phone_label.keys())[110]\n",
    "\n",
    "# label_list = list(phone_label_dev[utt])\n",
    "pred_label = model(torch.Tensor(feats[utt]).to(device))\n",
    "_, answer = torch.max(pred_label.data, 1)\n",
    "answer_list=list(answer.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt=\"SV0287_6_12_S2850\"\n",
    "\n",
    "# label_list = list(phone_label_dev[utt])\n",
    "pred_label = model(torch.Tensor(feats[utt]).to(device))\n",
    "_, answer = torch.max(pred_label.data, 1)\n",
    "answer_list=list(answer.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将预测结果映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(Data_show.phone2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title1, content1 = decoder.show_result(decoder.decode(torch.nn.Softmax()(pred_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title, content = Data_show().show_softmax(torch.nn.Softmax()(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsil\tnsn\tn\ti2\th\tao3\tm\ti3\tii\tia3\tother\n",
      " 0:\t0.97\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "1:\t0.96\t0.00\t0.00\t0.00\t0.01\t0.02\t0.00\t0.00\t0.00\t0.00\t\n",
      "2:\t0.99\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "3:\t0.99\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "4:\t0.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "5:\t0.98\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "6:\t0.93\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.06\t0.00\t\n",
      "7:\t0.98\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "8:\t0.93\t0.00\t0.00\t0.00\t0.03\t0.03\t0.00\t0.00\t0.01\t0.00\t\n",
      "9:\t0.98\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "10:\t0.84\t0.00\t0.00\t0.00\t0.15\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "11:\t0.96\t0.00\t0.00\t0.00\t0.03\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "12:\t0.97\t0.00\t0.00\t0.00\t0.02\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "13:\t0.93\t0.00\t0.00\t0.00\t0.06\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "14:\t0.98\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "15:\t0.91\t0.00\t0.00\t0.00\t0.04\t0.02\t0.00\t0.00\t0.03\t0.00\t\n",
      "16:\t0.96\t0.00\t0.00\t0.00\t0.02\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "17:\t0.98\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "18:\t0.97\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "19:\t0.90\t0.00\t0.00\t0.00\t0.06\t0.01\t0.00\t0.00\t0.03\t0.00\t\n",
      "20:\t0.96\t0.00\t0.00\t0.00\t0.02\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "21:\t0.86\t0.00\t0.00\t0.00\t0.01\t0.11\t0.01\t0.00\t0.01\t0.00\t\n",
      "22:\t0.92\t0.00\t0.00\t0.00\t0.01\t0.05\t0.00\t0.00\t0.01\t0.00\t\n",
      "23:\t0.85\t0.01\t0.00\t0.00\t0.00\t0.11\t0.01\t0.00\t0.00\t0.00\t\n",
      "24:\t0.63\t0.02\t0.00\t0.00\t0.00\t0.29\t0.06\t0.00\t0.00\t0.00\t\n",
      "25:\t0.49\t0.01\t0.00\t0.00\t0.00\t0.43\t0.07\t0.00\t0.00\t0.00\t\n",
      "26:\t0.72\t0.01\t0.00\t0.00\t0.00\t0.23\t0.04\t0.00\t0.00\t0.00\t\n",
      "27:\t0.58\t0.05\t0.00\t0.00\t0.00\t0.21\t0.15\t0.01\t0.00\t0.00\t\n",
      "28:\t0.42\t0.03\t0.00\t0.00\t0.00\t0.37\t0.18\t0.01\t0.00\t0.00\t\n",
      "29:\t0.40\t0.02\t0.00\t0.00\t0.00\t0.40\t0.18\t0.01\t0.00\t0.00\t\n",
      "30:\t0.30\t0.03\t0.00\t0.00\t0.00\t0.30\t0.35\t0.01\t0.00\t0.00\t\n",
      "31:\t0.23\t0.07\t0.00\t0.00\t0.00\t0.20\t0.48\t0.02\t0.00\t0.00\t\n",
      "32:\t0.20\t0.13\t0.00\t0.00\t0.00\t0.08\t0.56\t0.02\t0.00\t0.00\t\n",
      "33:\t0.23\t0.27\t0.00\t0.00\t0.00\t0.06\t0.39\t0.04\t0.00\t0.00\t\n",
      "34:\t0.37\t0.19\t0.01\t0.00\t0.00\t0.06\t0.35\t0.02\t0.00\t0.00\t\n",
      "35:\t0.11\t0.39\t0.00\t0.00\t0.00\t0.05\t0.39\t0.06\t0.00\t0.00\t\n",
      "36:\t0.04\t0.82\t0.00\t0.00\t0.00\t0.01\t0.06\t0.08\t0.00\t0.00\t\n",
      "37:\t0.06\t0.83\t0.00\t0.00\t0.00\t0.01\t0.06\t0.03\t0.00\t0.00\t\n",
      "38:\t0.17\t0.72\t0.00\t0.00\t0.02\t0.03\t0.03\t0.02\t0.00\t0.00\t\n",
      "39:\t0.23\t0.67\t0.00\t0.00\t0.00\t0.04\t0.05\t0.02\t0.00\t0.00\t\n",
      "40:\t0.10\t0.85\t0.00\t0.00\t0.00\t0.01\t0.02\t0.01\t0.00\t0.00\t\n",
      "41:\t0.22\t0.62\t0.01\t0.01\t0.02\t0.03\t0.03\t0.05\t0.02\t0.00\t\n",
      "42:\t0.02\t0.84\t0.05\t0.01\t0.00\t0.00\t0.00\t0.01\t0.07\t0.00\t\n",
      "43:\t0.03\t0.55\t0.05\t0.01\t0.00\t0.00\t0.00\t0.00\t0.36\t0.00\t\n",
      "44:\t0.01\t0.78\t0.07\t0.00\t0.00\t0.00\t0.00\t0.00\t0.13\t0.00\t\n",
      "45:\t0.02\t0.51\t0.38\t0.02\t0.00\t0.00\t0.00\t0.00\t0.07\t0.00\t\n",
      "46:\t0.01\t0.70\t0.25\t0.01\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t\n",
      "47:\t0.01\t0.42\t0.50\t0.05\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t\n",
      "48:\t0.01\t0.08\t0.81\t0.09\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t\n",
      "49:\t0.08\t0.08\t0.56\t0.10\t0.00\t0.00\t0.00\t0.00\t0.17\t0.00\t\n",
      "50:\t0.05\t0.29\t0.50\t0.04\t0.00\t0.00\t0.00\t0.00\t0.13\t0.00\t\n",
      "51:\t0.02\t0.05\t0.67\t0.21\t0.00\t0.00\t0.00\t0.00\t0.05\t0.00\t\n",
      "52:\t0.00\t0.15\t0.79\t0.05\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t\n",
      "53:\t0.03\t0.03\t0.59\t0.26\t0.00\t0.00\t0.00\t0.00\t0.08\t0.00\t\n",
      "54:\t0.20\t0.02\t0.39\t0.13\t0.16\t0.01\t0.00\t0.00\t0.09\t0.00\t\n",
      "55:\t0.05\t0.00\t0.10\t0.32\t0.48\t0.00\t0.00\t0.00\t0.05\t0.00\t\n",
      "56:\t0.13\t0.01\t0.30\t0.17\t0.30\t0.01\t0.00\t0.00\t0.07\t0.00\t\n",
      "57:\t0.15\t0.00\t0.07\t0.16\t0.46\t0.00\t0.00\t0.00\t0.16\t0.00\t\n",
      "58:\t0.09\t0.00\t0.17\t0.36\t0.23\t0.00\t0.00\t0.00\t0.15\t0.00\t\n",
      "59:\t0.00\t0.00\t0.00\t0.56\t0.43\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "60:\t0.00\t0.00\t0.00\t0.24\t0.76\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "61:\t0.00\t0.00\t0.00\t0.21\t0.79\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "62:\t0.00\t0.00\t0.00\t0.31\t0.69\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "63:\t0.00\t0.00\t0.00\t0.21\t0.79\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "64:\t0.00\t0.00\t0.00\t0.47\t0.53\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "65:\t0.00\t0.00\t0.00\t0.21\t0.79\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "66:\t0.00\t0.00\t0.00\t0.24\t0.76\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "67:\t0.00\t0.00\t0.00\t0.11\t0.89\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "68:\t0.00\t0.00\t0.00\t0.17\t0.82\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "69:\t0.00\t0.00\t0.00\t0.32\t0.67\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "70:\t0.00\t0.00\t0.00\t0.07\t0.93\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "71:\t0.00\t0.00\t0.00\t0.14\t0.86\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "72:\t0.00\t0.00\t0.00\t0.04\t0.95\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "73:\t0.01\t0.00\t0.00\t0.05\t0.94\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "74:\t0.01\t0.00\t0.00\t0.08\t0.91\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "75:\t0.02\t0.00\t0.00\t0.01\t0.97\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "76:\t0.02\t0.00\t0.00\t0.01\t0.97\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "77:\t0.02\t0.00\t0.00\t0.00\t0.98\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "78:\t0.04\t0.00\t0.00\t0.01\t0.95\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "79:\t0.01\t0.00\t0.00\t0.10\t0.89\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "80:\t0.02\t0.00\t0.00\t0.10\t0.88\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "81:\t0.05\t0.00\t0.00\t0.11\t0.83\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "82:\t0.23\t0.00\t0.00\t0.02\t0.64\t0.07\t0.03\t0.00\t0.00\t0.00\t\n",
      "83:\t0.71\t0.04\t0.00\t0.00\t0.01\t0.17\t0.03\t0.01\t0.03\t0.00\t\n",
      "84:\t0.51\t0.01\t0.01\t0.05\t0.21\t0.15\t0.02\t0.00\t0.03\t0.00\t\n",
      "85:\t0.69\t0.00\t0.00\t0.01\t0.10\t0.15\t0.02\t0.00\t0.03\t0.00\t\n",
      "86:\t0.71\t0.00\t0.00\t0.00\t0.00\t0.26\t0.02\t0.00\t0.00\t0.00\t\n",
      "87:\t0.64\t0.00\t0.00\t0.00\t0.00\t0.33\t0.02\t0.00\t0.00\t0.00\t\n",
      "88:\t0.73\t0.00\t0.00\t0.00\t0.05\t0.20\t0.01\t0.00\t0.00\t0.00\t\n",
      "89:\t0.68\t0.00\t0.00\t0.00\t0.01\t0.29\t0.01\t0.00\t0.00\t0.00\t\n",
      "90:\t0.59\t0.00\t0.00\t0.00\t0.04\t0.35\t0.03\t0.00\t0.00\t0.00\t\n",
      "91:\t0.64\t0.01\t0.00\t0.00\t0.00\t0.32\t0.02\t0.01\t0.00\t0.00\t\n",
      "92:\t0.39\t0.02\t0.00\t0.00\t0.00\t0.47\t0.12\t0.01\t0.00\t0.00\t\n",
      "93:\t0.58\t0.02\t0.00\t0.00\t0.00\t0.34\t0.05\t0.01\t0.00\t0.00\t\n",
      "94:\t0.63\t0.02\t0.00\t0.00\t0.00\t0.30\t0.05\t0.00\t0.00\t0.00\t\n",
      "95:\t0.78\t0.00\t0.00\t0.00\t0.00\t0.20\t0.01\t0.00\t0.00\t0.00\t\n",
      "96:\t0.76\t0.00\t0.00\t0.00\t0.00\t0.22\t0.01\t0.00\t0.00\t0.00\t\n",
      "97:\t0.41\t0.02\t0.00\t0.00\t0.00\t0.45\t0.11\t0.01\t0.00\t0.00\t\n",
      "98:\t0.44\t0.02\t0.00\t0.00\t0.00\t0.38\t0.16\t0.01\t0.00\t0.00\t\n",
      "99:\t0.60\t0.00\t0.00\t0.00\t0.00\t0.37\t0.02\t0.00\t0.00\t0.00\t\n",
      "100:\t0.48\t0.05\t0.00\t0.00\t0.00\t0.35\t0.10\t0.02\t0.00\t0.00\t\n",
      "101:\t0.23\t0.03\t0.00\t0.00\t0.01\t0.30\t0.24\t0.18\t0.01\t0.00\t\n",
      "102:\t0.32\t0.05\t0.00\t0.00\t0.00\t0.30\t0.31\t0.02\t0.00\t0.00\t\n",
      "103:\t0.26\t0.13\t0.00\t0.00\t0.00\t0.20\t0.38\t0.03\t0.00\t0.00\t\n",
      "104:\t0.38\t0.05\t0.00\t0.00\t0.00\t0.33\t0.23\t0.01\t0.00\t0.00\t\n",
      "105:\t0.33\t0.01\t0.00\t0.00\t0.00\t0.51\t0.14\t0.00\t0.00\t0.00\t\n",
      "106:\t0.36\t0.02\t0.00\t0.00\t0.00\t0.36\t0.25\t0.01\t0.00\t0.00\t\n",
      "107:\t0.50\t0.01\t0.00\t0.00\t0.00\t0.39\t0.10\t0.00\t0.00\t0.00\t\n",
      "108:\t0.34\t0.01\t0.00\t0.00\t0.00\t0.43\t0.21\t0.01\t0.00\t0.00\t\n",
      "109:\t0.44\t0.02\t0.00\t0.00\t0.00\t0.33\t0.20\t0.01\t0.00\t0.00\t\n",
      "110:\t0.35\t0.01\t0.00\t0.00\t0.00\t0.37\t0.26\t0.01\t0.00\t0.00\t\n",
      "111:\t0.23\t0.39\t0.00\t0.00\t0.00\t0.11\t0.19\t0.09\t0.00\t0.00\t\n",
      "112:\t0.25\t0.04\t0.03\t0.01\t0.01\t0.26\t0.36\t0.03\t0.00\t0.00\t\n",
      "113:\t0.11\t0.33\t0.01\t0.00\t0.01\t0.06\t0.14\t0.32\t0.01\t0.00\t\n",
      "114:\t0.08\t0.28\t0.00\t0.00\t0.01\t0.05\t0.16\t0.41\t0.01\t0.00\t\n",
      "115:\t0.02\t0.84\t0.00\t0.00\t0.00\t0.00\t0.00\t0.06\t0.08\t0.00\t\n",
      "116:\t0.01\t0.93\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.05\t0.00\t\n",
      "117:\t0.03\t0.07\t0.01\t0.00\t0.01\t0.01\t0.00\t0.02\t0.86\t0.00\t\n",
      "118:\t0.05\t0.05\t0.01\t0.00\t0.00\t0.00\t0.00\t0.01\t0.89\t0.00\t\n",
      "119:\t0.17\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.81\t0.00\t\n",
      "120:\t0.11\t0.00\t0.01\t0.02\t0.02\t0.00\t0.00\t0.00\t0.84\t0.00\t\n",
      "121:\t0.27\t0.03\t0.04\t0.01\t0.00\t0.00\t0.00\t0.00\t0.65\t0.00\t\n",
      "122:\t0.22\t0.02\t0.02\t0.01\t0.00\t0.00\t0.00\t0.00\t0.74\t0.00\t\n",
      "123:\t0.30\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.69\t0.00\t\n",
      "124:\t0.14\t0.00\t0.01\t0.08\t0.07\t0.00\t0.00\t0.00\t0.70\t0.00\t\n",
      "125:\t0.07\t0.08\t0.44\t0.15\t0.00\t0.00\t0.00\t0.00\t0.26\t0.00\t\n",
      "126:\t0.25\t0.00\t0.04\t0.12\t0.07\t0.00\t0.00\t0.00\t0.51\t0.00\t\n",
      "127:\t0.10\t0.00\t0.03\t0.24\t0.46\t0.00\t0.00\t0.00\t0.17\t0.00\t\n",
      "128:\t0.28\t0.00\t0.01\t0.21\t0.09\t0.00\t0.00\t0.00\t0.41\t0.00\t\n",
      "129:\t0.08\t0.00\t0.00\t0.33\t0.25\t0.00\t0.00\t0.00\t0.33\t0.00\t\n",
      "130:\t0.11\t0.00\t0.00\t0.18\t0.39\t0.00\t0.00\t0.00\t0.31\t0.00\t\n",
      "131:\t0.03\t0.00\t0.01\t0.23\t0.69\t0.00\t0.00\t0.00\t0.04\t0.00\t\n",
      "132:\t0.04\t0.00\t0.01\t0.21\t0.66\t0.00\t0.00\t0.00\t0.09\t0.00\t\n",
      "133:\t0.13\t0.00\t0.01\t0.14\t0.48\t0.00\t0.00\t0.00\t0.24\t0.00\t\n",
      "134:\t0.25\t0.00\t0.03\t0.08\t0.17\t0.00\t0.00\t0.00\t0.48\t0.00\t\n",
      "135:\t0.17\t0.00\t0.04\t0.14\t0.49\t0.00\t0.00\t0.00\t0.16\t0.00\t\n",
      "136:\t0.41\t0.00\t0.01\t0.02\t0.23\t0.00\t0.00\t0.00\t0.33\t0.00\t\n",
      "137:\t0.34\t0.00\t0.00\t0.03\t0.14\t0.00\t0.00\t0.00\t0.50\t0.00\t\n",
      "138:\t0.31\t0.00\t0.01\t0.02\t0.04\t0.00\t0.00\t0.00\t0.62\t0.00\t\n",
      "139:\t0.48\t0.00\t0.01\t0.02\t0.20\t0.00\t0.00\t0.00\t0.30\t0.00\t\n",
      "140:\t0.48\t0.00\t0.00\t0.00\t0.43\t0.00\t0.00\t0.00\t0.09\t0.00\t\n",
      "141:\t0.46\t0.00\t0.00\t0.00\t0.49\t0.00\t0.00\t0.00\t0.04\t0.00\t\n",
      "142:\t0.96\t0.00\t0.00\t0.00\t0.03\t0.01\t0.00\t0.00\t0.00\t0.00\t\n",
      "143:\t0.93\t0.00\t0.00\t0.00\t0.05\t0.01\t0.00\t0.00\t0.01\t0.00\t\n",
      "144:\t0.77\t0.00\t0.00\t0.00\t0.22\t0.00\t0.00\t0.00\t0.01\t0.00\t\n",
      "145:\t0.87\t0.00\t0.00\t0.00\t0.07\t0.01\t0.00\t0.00\t0.05\t0.00\t\n",
      "146:\t0.32\t0.00\t0.01\t0.01\t0.22\t0.00\t0.00\t0.00\t0.44\t0.00\t\n",
      "147:\t0.87\t0.00\t0.00\t0.00\t0.09\t0.01\t0.00\t0.00\t0.03\t0.00\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4,\n",
       "       4, 4, 4, 4, 4, 4, 0, 0, 5, 5, 5, 5, 5, 5, 6, 7, 7, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phone_cla_Dataset.class_trans_vector(phone_label[utt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### “你好米雅”测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_miya_test = { u:d for u,d in kaldi_io.read_mat_scp(\"/home1/meichaoyang/Dataset/feats/SLR85/far_field/train/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_miya_test=list(feats_miya_test.keys())[421]\n",
    "# utt_aishell=\"IC0001W0406\"\n",
    "\n",
    "pred_label_miya_test = model(torch.Tensor(feats_miya_test[utt_miya_test]).to(device))\n",
    "_, answer_miya_test = torch.max(pred_label_miya_test.data, 1)\n",
    "answer_miya_test_list=list(answer_miya_test.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/meichaoyang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "title, content = Data_show().show_softmax(torch.nn.Softmax()(pred_label_miya_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsil\tnsn\tn\ti2\th\tao3\tm\ti3\tii\tia3\tother\n",
      " 0:\t0.37\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t0.60\t0.00\t\n",
      "1:\t0.27\t0.02\t0.02\t0.01\t0.01\t0.01\t0.00\t0.00\t0.66\t0.00\t\n",
      "2:\t0.22\t0.08\t0.00\t0.00\t0.00\t0.03\t0.00\t0.00\t0.67\t0.00\t\n",
      "3:\t0.20\t0.01\t0.00\t0.00\t0.01\t0.05\t0.00\t0.00\t0.71\t0.01\t\n",
      "4:\t0.51\t0.01\t0.01\t0.00\t0.02\t0.03\t0.00\t0.00\t0.42\t0.00\t\n",
      "5:\t0.24\t0.21\t0.32\t0.04\t0.01\t0.03\t0.00\t0.00\t0.16\t0.00\t\n",
      "6:\t0.33\t0.27\t0.02\t0.00\t0.00\t0.06\t0.00\t0.03\t0.29\t0.00\t\n",
      "7:\t0.22\t0.58\t0.08\t0.00\t0.00\t0.10\t0.01\t0.00\t0.01\t0.00\t\n",
      "8:\t0.45\t0.36\t0.09\t0.01\t0.00\t0.07\t0.01\t0.00\t0.02\t0.00\t\n",
      "9:\t0.04\t0.38\t0.51\t0.05\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t\n",
      "10:\t0.06\t0.63\t0.19\t0.01\t0.00\t0.02\t0.00\t0.00\t0.09\t0.00\t\n",
      "11:\t0.08\t0.43\t0.29\t0.03\t0.00\t0.02\t0.00\t0.00\t0.14\t0.00\t\n",
      "12:\t0.18\t0.11\t0.04\t0.01\t0.00\t0.03\t0.00\t0.00\t0.62\t0.00\t\n",
      "13:\t0.22\t0.10\t0.02\t0.00\t0.00\t0.09\t0.00\t0.00\t0.57\t0.00\t\n",
      "14:\t0.05\t0.36\t0.43\t0.06\t0.00\t0.01\t0.00\t0.00\t0.09\t0.00\t\n",
      "15:\t0.17\t0.14\t0.08\t0.02\t0.00\t0.01\t0.00\t0.00\t0.58\t0.00\t\n",
      "16:\t0.25\t0.25\t0.03\t0.01\t0.01\t0.02\t0.00\t0.00\t0.42\t0.00\t\n",
      "17:\t0.33\t0.16\t0.08\t0.01\t0.00\t0.09\t0.00\t0.00\t0.33\t0.00\t\n",
      "18:\t0.21\t0.27\t0.14\t0.01\t0.00\t0.05\t0.00\t0.00\t0.31\t0.00\t\n",
      "19:\t0.08\t0.00\t0.00\t0.01\t0.04\t0.00\t0.00\t0.00\t0.87\t0.00\t\n",
      "20:\t0.60\t0.05\t0.00\t0.01\t0.04\t0.04\t0.00\t0.02\t0.20\t0.04\t\n",
      "21:\t0.34\t0.05\t0.03\t0.04\t0.05\t0.01\t0.00\t0.00\t0.41\t0.07\t\n",
      "22:\t0.24\t0.02\t0.02\t0.02\t0.03\t0.00\t0.00\t0.00\t0.59\t0.07\t\n",
      "23:\t0.43\t0.00\t0.00\t0.00\t0.07\t0.01\t0.00\t0.00\t0.48\t0.00\t\n",
      "24:\t0.47\t0.01\t0.01\t0.01\t0.07\t0.02\t0.00\t0.00\t0.42\t0.00\t\n",
      "25:\t0.12\t0.44\t0.28\t0.01\t0.00\t0.03\t0.00\t0.00\t0.04\t0.07\t\n",
      "26:\t0.35\t0.22\t0.03\t0.01\t0.01\t0.18\t0.00\t0.01\t0.11\t0.08\t\n",
      "27:\t0.18\t0.03\t0.02\t0.02\t0.01\t0.01\t0.00\t0.00\t0.03\t0.70\t\n",
      "28:\t0.43\t0.04\t0.03\t0.01\t0.12\t0.10\t0.00\t0.00\t0.25\t0.02\t\n",
      "29:\t0.14\t0.00\t0.02\t0.12\t0.36\t0.01\t0.00\t0.00\t0.29\t0.06\t\n",
      "30:\t0.18\t0.00\t0.01\t0.09\t0.25\t0.00\t0.00\t0.00\t0.45\t0.01\t\n",
      "31:\t0.29\t0.00\t0.03\t0.05\t0.14\t0.00\t0.00\t0.00\t0.44\t0.04\t\n",
      "32:\t0.17\t0.01\t0.06\t0.04\t0.05\t0.02\t0.00\t0.00\t0.12\t0.52\t\n",
      "33:\t0.27\t0.02\t0.01\t0.00\t0.01\t0.03\t0.00\t0.00\t0.67\t0.00\t\n",
      "34:\t0.56\t0.06\t0.00\t0.00\t0.01\t0.17\t0.00\t0.00\t0.16\t0.02\t\n",
      "35:\t0.37\t0.05\t0.00\t0.00\t0.01\t0.12\t0.00\t0.00\t0.44\t0.00\t\n",
      "36:\t0.69\t0.06\t0.01\t0.00\t0.00\t0.20\t0.03\t0.00\t0.01\t0.00\t\n",
      "37:\t0.13\t0.18\t0.02\t0.01\t0.00\t0.06\t0.01\t0.00\t0.01\t0.58\t\n",
      "38:\t0.06\t0.11\t0.01\t0.00\t0.00\t0.07\t0.04\t0.05\t0.00\t0.66\t\n",
      "39:\t0.01\t0.06\t0.03\t0.00\t0.00\t0.10\t0.05\t0.08\t0.00\t0.67\t\n",
      "40:\t0.01\t0.05\t0.02\t0.00\t0.00\t0.16\t0.04\t0.04\t0.00\t0.67\t\n",
      "41:\t0.08\t0.12\t0.02\t0.00\t0.00\t0.08\t0.07\t0.03\t0.00\t0.61\t\n",
      "42:\t0.05\t0.05\t0.01\t0.00\t0.00\t0.06\t0.04\t0.04\t0.00\t0.75\t\n",
      "43:\t0.02\t0.01\t0.01\t0.01\t0.00\t0.03\t0.02\t0.02\t0.00\t0.88\t\n",
      "44:\t0.01\t0.02\t0.01\t0.01\t0.00\t0.03\t0.02\t0.01\t0.00\t0.88\t\n",
      "45:\t0.01\t0.01\t0.01\t0.03\t0.00\t0.03\t0.01\t0.01\t0.00\t0.90\t\n",
      "46:\t0.00\t0.02\t0.01\t0.01\t0.00\t0.03\t0.01\t0.02\t0.00\t0.90\t\n",
      "47:\t0.05\t0.08\t0.01\t0.02\t0.00\t0.04\t0.02\t0.06\t0.56\t0.18\t\n",
      "48:\t0.06\t0.03\t0.01\t0.02\t0.01\t0.05\t0.02\t0.04\t0.78\t0.00\t\n",
      "49:\t0.16\t0.19\t0.06\t0.02\t0.01\t0.08\t0.02\t0.02\t0.42\t0.01\t\n",
      "50:\t0.04\t0.03\t0.07\t0.20\t0.07\t0.02\t0.01\t0.01\t0.55\t0.00\t\n",
      "51:\t0.02\t0.35\t0.13\t0.05\t0.00\t0.02\t0.01\t0.03\t0.39\t0.00\t\n",
      "52:\t0.01\t0.69\t0.10\t0.02\t0.00\t0.00\t0.00\t0.01\t0.15\t0.00\t\n",
      "53:\t0.00\t0.86\t0.10\t0.01\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t\n",
      "54:\t0.00\t0.85\t0.12\t0.01\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t\n",
      "55:\t0.00\t0.84\t0.13\t0.01\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t\n",
      "56:\t0.01\t0.64\t0.12\t0.01\t0.00\t0.00\t0.00\t0.00\t0.20\t0.00\t\n",
      "57:\t0.02\t0.69\t0.18\t0.01\t0.00\t0.00\t0.00\t0.00\t0.09\t0.00\t\n",
      "58:\t0.01\t0.61\t0.32\t0.03\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t\n",
      "59:\t0.03\t0.70\t0.16\t0.05\t0.00\t0.00\t0.00\t0.00\t0.05\t0.00\t\n",
      "60:\t0.06\t0.54\t0.19\t0.04\t0.00\t0.00\t0.00\t0.00\t0.17\t0.00\t\n",
      "61:\t0.04\t0.24\t0.38\t0.20\t0.00\t0.00\t0.00\t0.00\t0.13\t0.00\t\n",
      "62:\t0.07\t0.04\t0.06\t0.08\t0.01\t0.00\t0.00\t0.00\t0.75\t0.00\t\n",
      "63:\t0.01\t0.06\t0.25\t0.56\t0.03\t0.00\t0.00\t0.00\t0.09\t0.00\t\n",
      "64:\t0.02\t0.02\t0.17\t0.57\t0.03\t0.00\t0.00\t0.00\t0.18\t0.00\t\n",
      "65:\t0.00\t0.00\t0.00\t0.80\t0.19\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "66:\t0.00\t0.00\t0.00\t0.49\t0.50\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "67:\t0.01\t0.00\t0.01\t0.55\t0.29\t0.00\t0.00\t0.00\t0.11\t0.04\t\n",
      "68:\t0.00\t0.00\t0.00\t0.56\t0.41\t0.00\t0.00\t0.00\t0.01\t0.01\t\n",
      "69:\t0.00\t0.00\t0.00\t0.27\t0.73\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "70:\t0.01\t0.00\t0.00\t0.24\t0.23\t0.00\t0.00\t0.00\t0.00\t0.51\t\n",
      "71:\t0.00\t0.00\t0.00\t0.27\t0.65\t0.00\t0.00\t0.00\t0.00\t0.08\t\n",
      "72:\t0.00\t0.00\t0.00\t0.27\t0.71\t0.00\t0.00\t0.00\t0.01\t0.01\t\n",
      "73:\t0.00\t0.00\t0.00\t0.22\t0.74\t0.00\t0.00\t0.00\t0.00\t0.04\t\n",
      "74:\t0.00\t0.00\t0.00\t0.18\t0.82\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "75:\t0.00\t0.00\t0.00\t0.15\t0.85\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "76:\t0.00\t0.00\t0.00\t0.20\t0.80\t0.00\t0.00\t0.00\t0.00\t0.00\t\n",
      "77:\t0.00\t0.00\t0.00\t0.18\t0.81\t0.00\t0.00\t0.00\t0.01\t0.00\t\n",
      "78:\t0.01\t0.00\t0.00\t0.38\t0.54\t0.00\t0.00\t0.00\t0.07\t0.00\t\n",
      "79:\t0.00\t0.00\t0.00\t0.32\t0.65\t0.00\t0.00\t0.00\t0.03\t0.00\t\n",
      "80:\t0.00\t0.00\t0.00\t0.39\t0.57\t0.00\t0.00\t0.00\t0.03\t0.00\t\n",
      "81:\t0.00\t0.00\t0.00\t0.28\t0.70\t0.00\t0.00\t0.00\t0.01\t0.00\t\n",
      "82:\t0.02\t0.00\t0.00\t0.21\t0.71\t0.00\t0.00\t0.00\t0.07\t0.00\t\n",
      "83:\t0.06\t0.00\t0.00\t0.36\t0.36\t0.00\t0.00\t0.00\t0.22\t0.00\t\n",
      "84:\t0.04\t0.00\t0.00\t0.29\t0.38\t0.00\t0.00\t0.00\t0.29\t0.00\t\n",
      "85:\t0.02\t0.00\t0.00\t0.43\t0.36\t0.00\t0.00\t0.00\t0.19\t0.00\t\n",
      "86:\t0.03\t0.00\t0.00\t0.09\t0.83\t0.00\t0.00\t0.00\t0.05\t0.00\t\n",
      "87:\t0.10\t0.00\t0.00\t0.23\t0.46\t0.00\t0.00\t0.00\t0.20\t0.00\t\n",
      "88:\t0.14\t0.01\t0.01\t0.04\t0.04\t0.00\t0.00\t0.00\t0.76\t0.00\t\n",
      "89:\t0.29\t0.00\t0.00\t0.07\t0.20\t0.00\t0.00\t0.00\t0.43\t0.00\t\n",
      "90:\t0.16\t0.00\t0.00\t0.08\t0.04\t0.00\t0.00\t0.00\t0.72\t0.00\t\n",
      "91:\t0.12\t0.00\t0.01\t0.26\t0.04\t0.00\t0.00\t0.00\t0.56\t0.00\t\n",
      "92:\t0.17\t0.00\t0.01\t0.15\t0.28\t0.00\t0.00\t0.00\t0.38\t0.00\t\n",
      "93:\t0.24\t0.01\t0.12\t0.16\t0.02\t0.00\t0.00\t0.00\t0.46\t0.00\t\n",
      "94:\t0.19\t0.01\t0.01\t0.00\t0.02\t0.02\t0.00\t0.00\t0.75\t0.00\t\n",
      "95:\t0.26\t0.02\t0.07\t0.10\t0.05\t0.02\t0.00\t0.00\t0.48\t0.00\t\n",
      "96:\t0.23\t0.03\t0.09\t0.10\t0.02\t0.01\t0.00\t0.00\t0.49\t0.01\t\n",
      "97:\t0.26\t0.04\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.67\t0.00\t\n",
      "98:\t0.26\t0.05\t0.01\t0.00\t0.00\t0.08\t0.00\t0.00\t0.59\t0.00\t\n",
      "99:\t0.15\t0.00\t0.00\t0.00\t0.01\t0.02\t0.00\t0.00\t0.81\t0.00\t\n",
      "100:\t0.08\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.91\t0.00\t\n",
      "101:\t0.27\t0.01\t0.02\t0.03\t0.07\t0.04\t0.00\t0.00\t0.57\t0.00\t\n",
      "102:\t0.14\t0.00\t0.00\t0.17\t0.19\t0.00\t0.00\t0.00\t0.49\t0.00\t\n",
      "103:\t0.29\t0.02\t0.01\t0.03\t0.12\t0.01\t0.00\t0.00\t0.52\t0.00\t\n",
      "104:\t0.35\t0.01\t0.01\t0.03\t0.17\t0.02\t0.00\t0.00\t0.42\t0.00\t\n",
      "105:\t0.17\t0.00\t0.00\t0.04\t0.06\t0.00\t0.00\t0.00\t0.73\t0.00\t\n",
      "106:\t0.24\t0.01\t0.01\t0.01\t0.01\t0.00\t0.00\t0.00\t0.72\t0.00\t\n",
      "107:\t0.31\t0.00\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.65\t0.00\t\n",
      "108:\t0.34\t0.00\t0.01\t0.01\t0.03\t0.01\t0.00\t0.00\t0.60\t0.00\t\n",
      "109:\t0.34\t0.01\t0.01\t0.01\t0.05\t0.01\t0.00\t0.00\t0.57\t0.00\t\n",
      "110:\t0.30\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.69\t0.00\t\n",
      "111:\t0.22\t0.01\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.75\t0.00\t\n",
      "112:\t0.28\t0.01\t0.01\t0.01\t0.03\t0.01\t0.00\t0.00\t0.65\t0.00\t\n",
      "113:\t0.26\t0.01\t0.05\t0.04\t0.02\t0.00\t0.00\t0.00\t0.62\t0.00\t\n",
      "114:\t0.39\t0.00\t0.01\t0.03\t0.21\t0.01\t0.00\t0.00\t0.35\t0.00\t\n",
      "115:\t0.41\t0.02\t0.01\t0.00\t0.00\t0.02\t0.00\t0.00\t0.54\t0.00\t\n",
      "116:\t0.38\t0.00\t0.00\t0.00\t0.03\t0.41\t0.01\t0.00\t0.17\t0.00\t\n",
      "117:\t0.41\t0.00\t0.00\t0.00\t0.04\t0.11\t0.00\t0.00\t0.43\t0.00\t\n",
      "118:\t0.47\t0.00\t0.00\t0.00\t0.02\t0.46\t0.01\t0.00\t0.04\t0.00\t\n",
      "119:\t0.58\t0.00\t0.00\t0.00\t0.01\t0.29\t0.01\t0.00\t0.11\t0.00\t\n",
      "120:\t0.45\t0.00\t0.00\t0.00\t0.04\t0.13\t0.00\t0.00\t0.36\t0.00\t\n",
      "121:\t0.37\t0.02\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.60\t0.00\t\n",
      "122:\t0.39\t0.06\t0.01\t0.00\t0.01\t0.02\t0.00\t0.00\t0.50\t0.02\t\n",
      "123:\t0.41\t0.05\t0.03\t0.01\t0.02\t0.01\t0.00\t0.00\t0.46\t0.02\t\n",
      "124:\t0.18\t0.07\t0.00\t0.00\t0.00\t0.13\t0.26\t0.16\t0.15\t0.04\t\n",
      "125:\t0.04\t0.00\t0.01\t0.02\t0.00\t0.01\t0.01\t0.03\t0.00\t0.88\t\n",
      "126:\t0.05\t0.00\t0.00\t0.04\t0.00\t0.01\t0.01\t0.02\t0.00\t0.86\t\n",
      "127:\t0.07\t0.03\t0.01\t0.00\t0.00\t0.13\t0.22\t0.31\t0.13\t0.11\t\n",
      "128:\t0.06\t0.04\t0.00\t0.00\t0.00\t0.13\t0.16\t0.42\t0.06\t0.13\t\n",
      "129:\t0.05\t0.01\t0.01\t0.04\t0.00\t0.03\t0.04\t0.05\t0.00\t0.77\t\n",
      "130:\t0.02\t0.01\t0.01\t0.01\t0.00\t0.02\t0.05\t0.04\t0.00\t0.83\t\n",
      "131:\t0.05\t0.10\t0.00\t0.00\t0.00\t0.14\t0.47\t0.18\t0.00\t0.06\t\n",
      "132:\t0.08\t0.09\t0.00\t0.00\t0.00\t0.11\t0.54\t0.09\t0.01\t0.08\t\n",
      "133:\t0.05\t0.01\t0.01\t0.01\t0.00\t0.02\t0.03\t0.06\t0.00\t0.80\t\n",
      "134:\t0.05\t0.03\t0.01\t0.00\t0.00\t0.05\t0.04\t0.31\t0.02\t0.50\t\n",
      "135:\t0.03\t0.02\t0.00\t0.00\t0.00\t0.03\t0.04\t0.45\t0.07\t0.36\t\n",
      "136:\t0.02\t0.08\t0.00\t0.00\t0.00\t0.03\t0.10\t0.66\t0.08\t0.03\t\n",
      "137:\t0.02\t0.18\t0.00\t0.00\t0.00\t0.03\t0.13\t0.56\t0.08\t0.00\t\n",
      "138:\t0.01\t0.10\t0.00\t0.00\t0.00\t0.01\t0.04\t0.69\t0.12\t0.03\t\n",
      "139:\t0.02\t0.15\t0.00\t0.00\t0.00\t0.01\t0.02\t0.44\t0.35\t0.00\t\n",
      "140:\t0.01\t0.01\t0.00\t0.00\t0.00\t0.01\t0.00\t0.16\t0.63\t0.17\t\n",
      "141:\t0.04\t0.03\t0.00\t0.00\t0.01\t0.03\t0.02\t0.20\t0.65\t0.00\t\n",
      "142:\t0.04\t0.04\t0.00\t0.00\t0.00\t0.01\t0.00\t0.11\t0.79\t0.00\t\n",
      "143:\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.02\t0.16\t0.79\t\n",
      "144:\t0.02\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.03\t0.92\t\n",
      "145:\t0.03\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.40\t0.54\t\n",
      "146:\t0.02\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.52\t0.44\t\n",
      "147:\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.96\t0.03\t\n",
      "148:\t0.02\t0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "149:\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.96\t0.01\t\n",
      "150:\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.97\t0.00\t\n",
      "151:\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.97\t0.00\t\n",
      "152:\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "153:\t0.01\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.00\t0.05\t0.90\t\n",
      "154:\t0.05\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.95\t0.00\t\n",
      "155:\t0.04\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "156:\t0.06\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.93\t0.00\t\n",
      "157:\t0.05\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.93\t0.00\t\n",
      "158:\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "159:\t0.04\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.93\t0.02\t\n",
      "160:\t0.06\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.93\t0.00\t\n",
      "161:\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "162:\t0.02\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.95\t0.02\t\n",
      "163:\t0.03\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.96\t0.00\t\n",
      "164:\t0.08\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.91\t0.00\t\n",
      "165:\t0.16\t0.01\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.81\t0.00\t\n",
      "166:\t0.10\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.88\t0.00\t\n",
      "167:\t0.13\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.86\t0.00\t\n",
      "168:\t0.09\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.90\t0.00\t\n",
      "169:\t0.15\t0.00\t0.00\t0.01\t0.02\t0.00\t0.00\t0.00\t0.81\t0.00\t\n",
      "170:\t0.09\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.90\t0.00\t\n",
      "171:\t0.23\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.74\t0.00\t\n",
      "172:\t0.14\t0.02\t0.02\t0.01\t0.00\t0.01\t0.00\t0.00\t0.80\t0.00\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SV0002_2_08_S1171'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_miya_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非“你好米雅”测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_aishell = { u:d for u,d in kaldi_io.read_mat_scp(\"../wake_dnn_miya_only/feats_aishell2_test/feats.scp\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_aishell=list(feats_aishell.keys())[420]\n",
    "utt_aishell=\"IC0001W0406\"\n",
    "\n",
    "pred_label_aishell = model(torch.Tensor(feats_aishell[utt_aishell]).to(device))\n",
    "_, answer_aishell = torch.max(pred_label_aishell.data, 1)\n",
    "answer_aishell_list=list(answer_aishell.to(\"cpu\", torch.int).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.show_result(decoder.decode(torch.nn.Softmax()(pred_label_aishell)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_show().show_softmax(torch.nn.Softmax()(pred_label_aishell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_aishell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to(\"cpu\"), 'model.pkl')\n",
    "model1 = torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.jit.script(model1)\n",
    "sm.save(\"phone_cla_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
